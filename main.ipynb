{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datasets_dir = 'datasets'\n",
    "ecore_json_path = os.path.join(datasets_dir, 'ecore_555/ecore_555.jsonl')\n",
    "mar_json_path = os.path.join(datasets_dir, 'mar-ecore-github/ecore-github.jsonl')\n",
    "modelsets_uml_json_path = os.path.join(datasets_dir, 'modelset/uml.jsonl')\n",
    "modelsets_ecore_json_path = os.path.join(datasets_dir, 'modelset/ecore.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ecore_555 from pickle\n",
      "Loaded ecore_555 with 281 graphs\n",
      "Loaded ecore_555 with 281 graphs\n",
      "Graphs: 281\n"
     ]
    }
   ],
   "source": [
    "from data_loading.data import ModelDataset\n",
    "\n",
    "config_params = dict(\n",
    "    timeout = 120,\n",
    "    min_enr = 1.2,\n",
    "    min_edges = 10\n",
    ")\n",
    "ecore = ModelDataset('ecore_555', reload=False, **config_params)\n",
    "# modelset = ModelDataset('modelset', reload=False, remove_duplicates=True, **config_params)\n",
    "# mar = ModelDataset('mar-ecore-github', reload=False, **config_params)\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    'ecore': ecore,\n",
    "    # 'modelset': modelset,\n",
    "    # 'mar': mar\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4c1a356cc944bbb8f61de95b78ea88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ecore_555:   0%|          | 0/281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_loading.graph_dataset import GraphDataset\n",
    "\n",
    "graph_data_params = dict(\n",
    "    distance=2,\n",
    "    reload=False,\n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1,\n",
    "    use_edge_types=False,\n",
    ")\n",
    "\n",
    "ecore_graph_dataset = GraphDataset(ecore, **graph_data_params)\n",
    "# modelset_graph_dataset = GraphDataset(modelset, **graph_data_params)\n",
    "# mar_graph_dataset = GraphDataset(mar, **graph_data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gnn_layers import (\n",
    "    GATv2, \n",
    "    FeedForward, \n",
    "    GNNLinkPredictor\n",
    ")\n",
    "from trainers.link_predictor import GNNLinkPredictorTrainer\n",
    "\n",
    "\n",
    "input_dim = ecore_graph_dataset[0].x.size(1)\n",
    "hidden_dim = 64\n",
    "output_dim = 128\n",
    "num_layers = 3\n",
    "num_heads = 4\n",
    "edge_dim = ecore_graph_dataset[0].edge_attr.size(1)\n",
    "residual = True\n",
    "\n",
    "\n",
    "gat = GATv2(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads,\n",
    "    edge_dim=edge_dim,\n",
    "    residual=residual,\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "lp_head = FeedForward(\n",
    "    input_dim=(output_dim*num_heads if num_heads > 1 else output_dim) * 2,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=1,\n",
    "    num_layers=3,\n",
    ")\n",
    "\n",
    "ec_head = FeedForward(\n",
    "    input_dim=(output_dim*num_heads if num_heads > 1 else output_dim) * 2,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=3,\n",
    "    num_layers=3,\n",
    "    final_activation='softmax',\n",
    ")\n",
    "\n",
    "gnn_lp = GNNLinkPredictor(gat, lp_head, ec_head)\n",
    "lp_trainer = GNNLinkPredictorTrainer(\n",
    "    gnn_lp, \n",
    "    ecore_graph_dataset, \n",
    "    use_link_predictor=True, \n",
    "    use_edge_classifier=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_trainer.train_epochs(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6956, Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.loader import DataLoader\n",
    "# from torch_geometric.nn import GCNConv\n",
    "# from torch_geometric.nn.aggr import SortAggregation\n",
    "# import networkx as nx\n",
    "# from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "\n",
    "# def remap_node_indices(subgraph, center_node):\n",
    "#     mapping = {node: i for i, node in enumerate(subgraph.nodes())}\n",
    "#     subgraph = nx.relabel_nodes(subgraph, mapping)\n",
    "#     sub_edge_index = torch.tensor(list(subgraph.edges)).t().contiguous()\n",
    "#     sub_x = torch.ones(subgraph.number_of_nodes(), 1)  # Example node features\n",
    "#     center_node_idx = mapping[center_node]\n",
    "#     return sub_x, sub_edge_index, center_node_idx\n",
    "\n",
    "# # Prepare the train and test datasets for SEAL model\n",
    "# class SEALGraphData:\n",
    "#     def __init__(\n",
    "#             self, \n",
    "#             graph,\n",
    "#             edge_index,\n",
    "#             pos_edge_index,\n",
    "#             neg_edge_index,\n",
    "#             hops=1\n",
    "#         ):\n",
    "#         self.edge_index = edge_index\n",
    "#         self.pos_edge_index = pos_edge_index\n",
    "#         self.neg_edge_index = neg_edge_index\n",
    "#         self.graph = graph\n",
    "#         self.hops = hops\n",
    "\n",
    "\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.pos_edge_index.size(1) + self.neg_edge_index.size(1)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if idx < self.pos_edge_index.size(1):\n",
    "#             u, v = self.pos_edge_index[:, idx]\n",
    "#             y = 1\n",
    "#         else:\n",
    "#             u, v = self.neg_edge_index[:, idx - self.pos_edge_index.size(1)]\n",
    "#             y = 0\n",
    "\n",
    "#         subgraph = nx.ego_graph(self.graph, u.item(), radius=self.hops)\n",
    "#         subgraph = nx.subgraph(subgraph, list(subgraph.nodes) + [v.item()])\n",
    "#         sub_x, sub_edge_index, center_node_idx = remap_node_indices(subgraph, u.item())\n",
    "\n",
    "#         return Data(\n",
    "#             x=sub_x, \n",
    "#             edge_index=sub_edge_index, \n",
    "#             y=y, \n",
    "#             center_node_idx=center_node_idx\n",
    "#         )\n",
    "\n",
    "\n",
    "# def get_link_prediction_train_test_graph_data(\n",
    "#         graph, \n",
    "#         num_val=0, \n",
    "#         num_test=0.2, \n",
    "#         add_negative_train_samples=True,\n",
    "#         neg_sampling_ratio=1,\n",
    "#     ):\n",
    "#     transform = RandomLinkSplit(\n",
    "#         num_val=num_val, \n",
    "#         num_test=num_test, \n",
    "#         neg_sampling_ratio=neg_sampling_ratio,\n",
    "#         add_negative_train_samples=add_negative_train_samples,\n",
    "#         split_labels=True\n",
    "#     )\n",
    "\n",
    "#     # Apply the transform\n",
    "#     train_data, _, test_data = transform(\n",
    "#         Data(\n",
    "#             edge_index=graph.edge_index, \n",
    "#             num_nodes=ecore_graph.number_of_nodes()\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     return train_data, test_data\n",
    "\n",
    "#     # train_graph_data = SEALGraphData(\n",
    "#     #     graph, \n",
    "#     #     train_data.edge_index, \n",
    "#     #     train_data.pos_edge_label_index, \n",
    "#     #     train_data.neg_edge_label_index,\n",
    "#     #     hops=hops\n",
    "    \n",
    "#     # )\n",
    "\n",
    "#     # test_graph_data = SEALGraphData(\n",
    "#     #     graph, \n",
    "#     #     test_data.edge_index, \n",
    "#     #     test_data.pos_edge_label_index, \n",
    "#     #     test_data.neg_edge_label_index,\n",
    "#     #     hops=hops\n",
    "#     # )\n",
    "\n",
    "#     # return train_graph_data, test_graph_data\n",
    "    \n",
    "\n",
    "# train_data, test_data = get_link_prediction_train_test_graph_data(ecore_graph)\n",
    "# # Create train and test dataloaders\n",
    "# batch_size = 32\n",
    "\n",
    "# # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# # test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gnn_layers import GNNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
