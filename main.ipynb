{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading eamodelset from pickle\n",
      "Loaded eamodelset with 558 graphs\n",
      "Loaded eamodelset with 558 graphs\n",
      "Graphs: 558\n",
      "Loading modelset from pickle\n",
      "Loaded modelset with 2539 graphs\n",
      "Loaded modelset with 2539 graphs\n",
      "Loading ontouml from pickle\n",
      "Loaded ontouml with 175 graphs\n",
      "Loaded ontouml with 175 graphs\n",
      "Graphs: 175\n"
     ]
    }
   ],
   "source": [
    "from utils import set_seed\n",
    "from data_loading.models_dataset import ArchiMateDataset, EcoreDataset, OntoUMLDataset\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "config_params = dict(\n",
    "    # reload=True,\n",
    "    min_enr = -1,\n",
    "    min_edges = 10,\n",
    "    # language = 'en',\n",
    ")\n",
    "\n",
    "dataset = ArchiMateDataset('eamodelset', **config_params)\n",
    "dataset = EcoreDataset('modelset', **config_params)\n",
    "dataset = OntoUMLDataset('ontouml', **config_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_graphs': 175,\n",
       " 'num_edges': 20220,\n",
       " 'num_nodes': 15890,\n",
       " 'average_nodes': '90.80',\n",
       " 'average_edges': '115.54',\n",
       " 'average_n2e_ratio': '0.83'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph dataset\n",
      "Number of duplicate graphs:  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21786ab9000f4b15aad31470dbcd6458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating node graphs:   0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe98842841d847acaa569954af113587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding graphs:   0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1114077e538b400d96de08a237807808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-Loading graphs:   0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'abstract' 'abstract individual' 'activity' 'agent' 'atomic event'\n",
      " 'being present at ' 'belief' 'bringsabout' 'category' 'causal'\n",
      " 'characterization' 'collective' 'commitment' 'comparative'\n",
      " 'complex event' 'complexaction' 'complexevent' 'componentof' 'constitute'\n",
      " 'cr' 'crd' 'creation' 'cru' 'crud' 'datatype' 'derivation' 'disposition'\n",
      " 'endurant' 'enumeration' 'event' 'externaldependence' 'formal' 'goal'\n",
      " 'has part' 'historicaldependence' 'historicalrole' 'historicalrolemixin'\n",
      " 'humanagent' 'induces' 'instantiation' 'institutionalagent' 'intention'\n",
      " 'internal' 'kind' 'manifestation' 'material' 'material relation'\n",
      " 'mediation' 'memberof' 'mentalmode' 'mixin' 'mode' 'natural'\n",
      " 'nonperceivablequality' 'normative description' 'object' 'organization'\n",
      " 'part-of' 'participation' 'participational' 'partof' 'phase' 'phasemixin'\n",
      " 'pos-state' 'post state' 'pre-state' 'presentat' 'processual role'\n",
      " 'proposition' 'quale' 'quality' 'quality dimension' 'quality structure'\n",
      " 'quantity' 'r' 'relator' 'role' 'rolemixin' 'ru' 'service' 'set'\n",
      " 'situation' 'stringnominalstructure' 'structuration' 'subcollectionof'\n",
      " 'subkind' 'subquantityof' 'sum' 'termination' 'timepoint' 'triggers'\n",
      " 'trope' 'type' 'ufo-b' 'ufo-c' 'viewpoint']\n",
      "Setting num_nodes_ stereotype 96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac63cb5eb0d54c00a22735ef202014c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating node classes:   0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96}\n",
      "Test classes: {0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 62, 63, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93}\n",
      "Number of classes in training set: 86\n",
      "Number of classes in test set: 74\n",
      "Edge Classes:  [None]\n",
      "Graphs saved\n",
      "Node label: stereotype\n",
      "Train Node classes: {59: 183, 86: 1209, 77: 913, 30: 377, 71: 214, 11: 397, 22: 47, 60: 16, 0: 2635, 44: 1144, 76: 556, 62: 255, 48: 1092, 9: 414, 18: 394, 32: 294, 78: 316, 52: 314, 88: 15, 12: 121, 46: 465, 31: 63, 49: 117, 26: 175, 25: 103, 51: 40, 66: 8, 39: 21, 82: 62, 36: 18, 6: 13, 74: 18, 65: 4, 29: 38, 93: 160, 47: 3, 27: 6, 69: 5, 85: 27, 45: 28, 8: 26, 40: 50, 91: 13, 35: 39, 63: 15, 37: 7, 1: 1, 5: 3, 64: 5, 19: 2, 84: 3, 24: 3, 75: 1, 79: 2, 23: 1, 87: 10, 14: 33, 17: 1, 16: 1, 53: 1, 56: 5, 4: 2, 7: 1, 61: 2, 89: 5, 10: 31, 70: 1, 2: 1, 72: 1, 81: 2, 96: 1, 90: 1, 58: 1, 34: 1, 92: 2, 80: 1, 13: 1, 15: 2, 68: 6, 38: 1, 41: 1, 55: 4, 54: 5, 67: 6, 95: 2, 94: 1}\n",
      "Test Node classes: {30: 97, 86: 299, 44: 331, 48: 292, 11: 92, 76: 155, 59: 46, 0: 679, 77: 231, 71: 55, 22: 13, 9: 108, 78: 71, 18: 116, 32: 59, 52: 79, 25: 23, 36: 5, 39: 4, 6: 1, 82: 17, 12: 29, 26: 46, 46: 116, 62: 59, 49: 23, 69: 3, 93: 37, 27: 1, 51: 11, 45: 6, 40: 19, 35: 5, 37: 2, 63: 5, 5: 1, 74: 7, 19: 1, 29: 14, 84: 2, 24: 1, 20: 1, 21: 1, 75: 2, 79: 1, 85: 3, 60: 1, 14: 5, 31: 14, 43: 1, 87: 2, 33: 1, 42: 1, 4: 1, 8: 4, 61: 1, 91: 3, 10: 6, 73: 1, 28: 1, 90: 1, 13: 1, 92: 2, 88: 3, 50: 1, 3: 1, 57: 1, 55: 2, 54: 1, 1: 1, 83: 1, 68: 2, 67: 2, 66: 1}\n",
      "Loaded graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb59315de0554808b1023f1a68863bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting node classification data:   0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data\n",
      "['Source Rock  stereotype: kind Lithologic Unit qua shale', 'Oil  stereotype: quantity Hidrocarbon\\nOil\\nOil\\nOil', 'stereotype: event Acumulation', 'Migration  stereotype: pos-state', 'Hidrocarbon', 'Generation  stereotype: pos-state', 'Trap', 'Oil + Porous rock  stereotype: pre-state', 'Shale  stereotype: quantity Siliciclastic Rock', 'Structure']\n",
      "['Seal  stereotype: kind Lithologic Unit qua shale\\nSeal', 'stereotype: quantity Siliciclastic Rock', 'Sandstone  stereotype: quantity Siliciclastic Rock', 'stereotype: quantity Shale', 'Boundary Type', 'Value', 'stereotype: quantity Siliciclastic Rock', 'Lithologic Unit qua sandstone  stereotype: kind Lithological unit\\nLithologic Unit qua sandstone\\nLithologic Unit qua sandstone\\nLithologic Unit qua sandstone  stereotype: constitute', 'Business Need  stereotype: material is Demanded By', 'End Product  Value Object\\nEnd Product  has Objective Value\\nEnd Product  satisfies\\nEnd Product  has Objective Value\\nEnd Product  stock Flow']\n",
      "9949\n",
      "9949\n",
      "2552\n",
      "2552\n"
     ]
    }
   ],
   "source": [
    "from data_loading.graph_dataset import GraphNodeDataset\n",
    "import utils\n",
    "\n",
    "utils.set_seed(42)\n",
    "\n",
    "graph_data_params = dict(\n",
    "    reload=True,\n",
    "    test_ratio=0.2,\n",
    "    # add_negative_train_samples=True,\n",
    "    # neg_sampling_ratio=1,\n",
    "    distance=1,\n",
    "    random_embed_dim=128,\n",
    "    use_attributes=False,\n",
    "    use_edge_label=True,\n",
    "    use_edge_types=True,\n",
    "    use_node_types=True,\n",
    "    \n",
    "    node_cls_label='stereotype',\n",
    "    # use_special_tokens=True,\n",
    "    # task_type='graph_cls',\n",
    "    # use_embeddings=True,\n",
    "    # embed_model_name='bert-base-cased',\n",
    "    # ckpt='results/eamodelset/lp/10_att_0_nt_0/checkpoint-177600',\n",
    "    limit = -1,\n",
    ")\n",
    "\n",
    "print(\"Loading graph dataset\")\n",
    "graph_node_dataset = GraphNodeDataset(dataset, **graph_data_params)\n",
    "print(\"Loaded graph dataset\")\n",
    "\n",
    "texts = graph_node_dataset.get_node_classification_texts(distance=1, label='stereotype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization.utils import get_tokenizer\n",
    "\n",
    "\n",
    "tokenizer = get_tokenizer('bert-base-uncased')\n",
    "for data in graph_node_dataset.get_kfold_lm_graph_classification_data(tokenizer):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fname):\n",
    "\twith open(fname) as f:\n",
    "\t\tdata = f.read().split('\\n')\n",
    "\t\ttexts, labels = [], []\n",
    "\t\tfor line in data:\n",
    "\t\t\tif not line:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\ttry:\n",
    "\t\t\t\ttexts.append(line.split(\", Text: \")[1])\n",
    "\t\t\t\tlabels.append(line.split(\", Text: \")[0].split(\"Label: \")[1])\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(line)\n",
    "\t\t\t\traise e\n",
    "\treturn texts, labels\n",
    "\n",
    "X_train, y_train = get_data('train.txt')\n",
    "X_test, y_test = get_data('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1606, 1606)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = X_train + X_test, y_train + y_test\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1284 322 1284 322\n",
      "Counter({'statemachine': 93, 'gpl': 84, 'class-diagram': 74, 'modelling': 64, 'simple-pl': 59, 'iot': 51, 'workflow': 48, 'relational': 47, 'transformation': 45, 'petrinet': 44, 'metamodelling': 37, 'robots': 34, 'webapp': 33, 'features': 32, 'education': 29, 'library': 24, 'constraints': 24, 'graphicaleditor': 23, 'visualization': 21, 'components': 20, 'expressions': 19, 'types': 18, 'entities': 17, 'services': 16, 'trace': 14, 'company': 14, 'mvc': 14, 'publication': 13, 'enterprisearchitecture': 13, 'architecture': 12, 'forms': 12, 'calculator': 12, 'drones': 12, 'metrics': 11, 'testing': 11, 'hotels': 11, 'purchases': 11, 'app': 11, 'relationships': 10, 'embedded': 10, 'modelmanagement': 9, 'families': 9, 'cloud': 9, 'projectplanning': 9, 'html': 8, 'graph': 8, 'automata': 7, 'rental': 7, 'interaction': 7, 'gui': 6, 'textprocessing': 5, 'termrewriting': 5, 'softwarerepository': 5, 'configuration': 5, 'requirements': 5, 'tournament': 5, 'activities': 5, 'railway': 4, 'timed-automata': 4, 'fault-tree': 4, 'people': 4, 'units': 3, 'bibliography': 3, 'employees': 1})\n",
      "Counter({'statemachine': 22, 'class-diagram': 21, 'simple-pl': 18, 'education': 16, 'graphicaleditor': 14, 'gpl': 14, 'modelling': 13, 'relational': 13, 'transformation': 12, 'workflow': 12, 'petrinet': 12, 'metamodelling': 9, 'webapp': 8, 'enterprisearchitecture': 8, 'entities': 7, 'interaction': 7, 'iot': 6, 'types': 6, 'constraints': 6, 'relationships': 6, 'families': 6, 'trace': 5, 'robots': 5, 'hotels': 4, 'features': 4, 'activities': 4, 'automata': 4, 'metrics': 4, 'visualization': 3, 'publication': 3, 'railway': 3, 'graph': 3, 'mvc': 3, 'components': 3, 'company': 3, 'expressions': 3, 'timed-automata': 2, 'html': 2, 'requirements': 2, 'purchases': 2, 'calculator': 2, 'library': 2, 'app': 2, 'gui': 2, 'modelmanagement': 2, 'architecture': 2, 'testing': 2, 'services': 1, 'fault-tree': 1, 'drones': 1, 'forms': 1, 'embedded': 1, 'termrewriting': 1, 'tree': 1, 'projectplanning': 1, 'bibliography': 1, 'units': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVM classifier\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svc, total=   1.2s\n",
      "Predicting\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "            activities       0.00      0.00      0.00         4\n",
      "                   app       0.50      0.50      0.50         2\n",
      "          architecture       1.00      0.50      0.67         2\n",
      "              automata       1.00      0.25      0.40         4\n",
      "          bibliography       1.00      1.00      1.00         1\n",
      "            calculator       1.00      0.50      0.67         2\n",
      "         class-diagram       0.88      1.00      0.93        21\n",
      "               company       1.00      1.00      1.00         3\n",
      "            components       0.75      1.00      0.86         3\n",
      "           constraints       0.75      1.00      0.86         6\n",
      "                drones       0.50      1.00      0.67         1\n",
      "             education       1.00      1.00      1.00        16\n",
      "              embedded       0.00      0.00      0.00         1\n",
      "enterprisearchitecture       1.00      0.62      0.77         8\n",
      "              entities       0.86      0.86      0.86         7\n",
      "           expressions       0.40      0.67      0.50         3\n",
      "              families       1.00      0.67      0.80         6\n",
      "            fault-tree       1.00      1.00      1.00         1\n",
      "              features       1.00      1.00      1.00         4\n",
      "                 forms       0.50      1.00      0.67         1\n",
      "                   gpl       0.63      0.86      0.73        14\n",
      "                 graph       0.67      0.67      0.67         3\n",
      "       graphicaleditor       1.00      0.93      0.96        14\n",
      "                   gui       1.00      0.50      0.67         2\n",
      "                hotels       0.80      1.00      0.89         4\n",
      "                  html       1.00      1.00      1.00         2\n",
      "           interaction       1.00      0.86      0.92         7\n",
      "                   iot       0.42      0.83      0.56         6\n",
      "               library       1.00      1.00      1.00         2\n",
      "         metamodelling       0.88      0.78      0.82         9\n",
      "               metrics       1.00      1.00      1.00         4\n",
      "             modelling       0.67      0.77      0.71        13\n",
      "       modelmanagement       0.00      0.00      0.00         2\n",
      "                   mvc       1.00      1.00      1.00         3\n",
      "              petrinet       1.00      0.92      0.96        12\n",
      "       projectplanning       1.00      1.00      1.00         1\n",
      "           publication       1.00      1.00      1.00         3\n",
      "             purchases       1.00      1.00      1.00         2\n",
      "               railway       1.00      1.00      1.00         3\n",
      "            relational       1.00      1.00      1.00        13\n",
      "         relationships       1.00      1.00      1.00         6\n",
      "          requirements       0.00      0.00      0.00         2\n",
      "                robots       0.50      0.20      0.29         5\n",
      "              services       0.00      0.00      0.00         1\n",
      "             simple-pl       0.75      0.83      0.79        18\n",
      "          statemachine       0.80      0.91      0.85        22\n",
      "         termrewriting       1.00      1.00      1.00         1\n",
      "               testing       0.00      0.00      0.00         2\n",
      "        timed-automata       0.00      0.00      0.00         2\n",
      "                 trace       0.83      1.00      0.91         5\n",
      "        transformation       0.82      0.75      0.78        12\n",
      "                  tree       0.00      0.00      0.00         1\n",
      "                 types       0.57      0.67      0.62         6\n",
      "                 units       0.00      0.00      0.00         1\n",
      "         visualization       0.60      1.00      0.75         3\n",
      "                webapp       1.00      0.75      0.86         8\n",
      "              workflow       0.73      0.92      0.81        12\n",
      "\n",
      "              accuracy                           0.82       322\n",
      "             macro avg       0.72      0.71      0.70       322\n",
      "          weighted avg       0.80      0.82      0.80       322\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7139958968906337"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "\n",
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'), verbose=True)\n",
    "\n",
    "print(\"Fitting SVM classifier\")\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Predicting\")\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from transformers import (\n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer\n",
    ")\n",
    "from data_loading.encoding import EncodingDataset\n",
    "from settings import device\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from trainers.metrics import compute_metrics\n",
    "\n",
    "\n",
    "class BertTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        ckpt=None,\n",
    "        max_length=512\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.ckpt = ckpt\n",
    "        self.max_length = max_length\n",
    "\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        texts,\n",
    "        labels,\n",
    "        test_ratio=0.2,\n",
    "        kfold=False,\n",
    "        num_train_epochs=15,\n",
    "        train_batch_size=2,\n",
    "        eval_batch_size=128,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        eval_steps=50,\n",
    "        save_steps=50,\n",
    "        learning_rate=5e-5,\n",
    "        warmup_steps=500,\n",
    "        output_dir='./results',\n",
    "        logs_dir='./logs',\n",
    "        seed=42\n",
    "    ):\n",
    "        def train_fold():\n",
    "            print(f'Train: {len(X_train)}, Test: {len(X_test)}')\n",
    "            print(\"Class distribution in train: \", Counter(y_train))\n",
    "            print(\"Class distribution in test: \", Counter(y_test))\n",
    "\n",
    "            tokenizer = AutoTokenizer.from_pretrained(self.model_name if not self.ckpt else self.ckpt)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=num_classes)\n",
    "            model.to(device)\n",
    "\n",
    "            train_ds = EncodingDataset(tokenizer, X_train, y_train, max_length=self.max_length)\n",
    "            test_ds = EncodingDataset(tokenizer, X_test, y_test, max_length=self.max_length)\n",
    "\n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=output_dir,\n",
    "                num_train_epochs=num_train_epochs,\n",
    "                eval_strategy=\"steps\",\n",
    "                per_device_train_batch_size=train_batch_size,\n",
    "                per_device_eval_batch_size=eval_batch_size,\n",
    "                warmup_steps=warmup_steps,\n",
    "                weight_decay=weight_decay,\n",
    "                learning_rate=learning_rate,\n",
    "                logging_dir=logs_dir,\n",
    "                logging_steps=logging_steps,\n",
    "                eval_steps=eval_steps,\n",
    "                save_steps=save_steps,\n",
    "                save_total_limit=2,\n",
    "                load_best_model_at_end=True,\n",
    "                fp16=True\n",
    "            )\n",
    "\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_ds,\n",
    "                eval_dataset=test_ds,\n",
    "                compute_metrics=compute_metrics            \n",
    "            )\n",
    "\n",
    "            trainer.train()\n",
    "            results = trainer.evaluate()\n",
    "            print(results)\n",
    "\n",
    "\n",
    "        y = LabelEncoder().fit_transform(labels)\n",
    "        num_classes = len(set(y))\n",
    "        if kfold > 0:\n",
    "            k = int(1 / self.test_ratio)\n",
    "            kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "            n = len(self.graphs)\n",
    "            for i, (train_idx, test_idx) in enumerate(kfold.split(np.zeros(n), np.zeros(n))):\n",
    "                X_train, y_train = [texts[i] for i in train_idx], [y[i] for i in train_idx]\n",
    "                X_test, y_test = [texts[i] for i in test_idx], [y[i] for i in test_idx]\n",
    "                print(\"Fold number: \", i+1)\n",
    "                train_fold()\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(texts, y, test_size=test_ratio, random_state=seed)\n",
    "            train_fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1284, Test: 322\n",
      "Class distribution in train:  Counter({23: 92, 51: 89, 6: 75, 34: 66, 49: 62, 64: 48, 38: 46, 58: 45, 43: 43, 30: 41, 13: 39, 32: 36, 25: 31, 63: 30, 21: 26, 47: 25, 60: 24, 17: 23, 11: 22, 31: 22, 18: 20, 62: 19, 16: 17, 8: 16, 36: 15, 57: 14, 9: 14, 48: 13, 33: 13, 40: 13, 5: 12, 53: 11, 27: 11, 44: 11, 3: 10, 19: 10, 35: 10, 41: 10, 2: 9, 22: 9, 7: 9, 1: 9, 39: 9, 24: 9, 28: 8, 29: 8, 0: 8, 12: 8, 45: 7, 14: 7, 55: 6, 26: 6, 46: 6, 42: 6, 56: 5, 54: 5, 10: 4, 20: 4, 61: 4, 52: 4, 4: 3, 50: 3, 37: 2, 59: 1, 15: 1})\n",
      "Class distribution in test:  Counter({51: 26, 6: 20, 43: 17, 30: 16, 49: 15, 47: 14, 64: 12, 58: 12, 63: 11, 34: 11, 32: 10, 21: 10, 38: 10, 9: 9, 11: 8, 29: 6, 25: 6, 13: 6, 23: 6, 44: 5, 57: 5, 12: 5, 19: 5, 2: 5, 62: 5, 48: 4, 16: 4, 14: 4, 22: 4, 27: 4, 1: 4, 31: 4, 40: 3, 41: 3, 28: 2, 33: 2, 37: 2, 50: 2, 26: 2, 18: 2, 36: 2, 5: 2, 53: 2, 52: 2, 24: 2, 10: 1, 35: 1, 3: 1, 39: 1, 46: 1, 8: 1, 17: 1, 4: 1, 20: 1, 0: 1, 42: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Dataset created with 1284 samples\n",
      "Encoding Dataset created with 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2415' max='2415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2415/2415 34:29, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.173700</td>\n",
       "      <td>4.152552</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.022186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.029600</td>\n",
       "      <td>3.937557</td>\n",
       "      <td>0.090062</td>\n",
       "      <td>0.048008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.807100</td>\n",
       "      <td>3.693329</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.066659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.535600</td>\n",
       "      <td>3.399808</td>\n",
       "      <td>0.251553</td>\n",
       "      <td>0.126848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.198800</td>\n",
       "      <td>3.040430</td>\n",
       "      <td>0.403727</td>\n",
       "      <td>0.209241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.864500</td>\n",
       "      <td>2.775781</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.228524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.555800</td>\n",
       "      <td>2.431179</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.364319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.171300</td>\n",
       "      <td>2.107372</td>\n",
       "      <td>0.583851</td>\n",
       "      <td>0.392884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.909400</td>\n",
       "      <td>1.888310</td>\n",
       "      <td>0.618012</td>\n",
       "      <td>0.446488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.648900</td>\n",
       "      <td>1.677718</td>\n",
       "      <td>0.664596</td>\n",
       "      <td>0.510141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.309500</td>\n",
       "      <td>1.500758</td>\n",
       "      <td>0.701863</td>\n",
       "      <td>0.563292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.280800</td>\n",
       "      <td>1.373551</td>\n",
       "      <td>0.729814</td>\n",
       "      <td>0.599051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>1.258365</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.580121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.891700</td>\n",
       "      <td>1.078575</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.635818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>1.001270</td>\n",
       "      <td>0.807453</td>\n",
       "      <td>0.654493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.987014</td>\n",
       "      <td>0.795031</td>\n",
       "      <td>0.670889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.537700</td>\n",
       "      <td>0.858375</td>\n",
       "      <td>0.841615</td>\n",
       "      <td>0.727534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.530900</td>\n",
       "      <td>0.818442</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.707372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.424600</td>\n",
       "      <td>0.860691</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.744324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.335600</td>\n",
       "      <td>0.775187</td>\n",
       "      <td>0.832298</td>\n",
       "      <td>0.762479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.781709</td>\n",
       "      <td>0.844720</td>\n",
       "      <td>0.784062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>0.755492</td>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.788996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.181800</td>\n",
       "      <td>0.758496</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.784574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.740541</td>\n",
       "      <td>0.860248</td>\n",
       "      <td>0.796237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.804523</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.787173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.831067</td>\n",
       "      <td>0.863354</td>\n",
       "      <td>0.793002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>0.795836</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.791503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.822515</td>\n",
       "      <td>0.860248</td>\n",
       "      <td>0.813308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.810379</td>\n",
       "      <td>0.866460</td>\n",
       "      <td>0.815986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>0.802914</td>\n",
       "      <td>0.860248</td>\n",
       "      <td>0.809800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.831365</td>\n",
       "      <td>0.863354</td>\n",
       "      <td>0.815380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.823635</td>\n",
       "      <td>0.863354</td>\n",
       "      <td>0.809059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.851872</td>\n",
       "      <td>0.863354</td>\n",
       "      <td>0.806926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.886518</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.809902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.868028</td>\n",
       "      <td>0.866460</td>\n",
       "      <td>0.818969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.858133</td>\n",
       "      <td>0.866460</td>\n",
       "      <td>0.817640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.909100</td>\n",
       "      <td>0.866460</td>\n",
       "      <td>0.817268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.889316</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.816599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.910914</td>\n",
       "      <td>0.872671</td>\n",
       "      <td>0.819575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.911062</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>0.822551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.916368</td>\n",
       "      <td>0.872671</td>\n",
       "      <td>0.824709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.947466</td>\n",
       "      <td>0.872671</td>\n",
       "      <td>0.820616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.948768</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>0.824783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.963535</td>\n",
       "      <td>0.878882</td>\n",
       "      <td>0.827015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.963308</td>\n",
       "      <td>0.878882</td>\n",
       "      <td>0.827015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.878882</td>\n",
       "      <td>0.827015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.972063</td>\n",
       "      <td>0.872671</td>\n",
       "      <td>0.820319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.970248</td>\n",
       "      <td>0.872671</td>\n",
       "      <td>0.820319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.740541398525238, 'eval_accuracy': 0.860248447204969, 'eval_balanced_accuracy': 0.796237088949799, 'eval_runtime': 0.7368, 'eval_samples_per_second': 436.997, 'eval_steps_per_second': 1.357, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2466: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "bert_trainer = BertTrainer('bert-base-uncased')\n",
    "bert_trainer.train(X, y, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69badd34553473dac8554c0b49f4441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting edge_cls data:   0%|          | 0/543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Texts:  ['<node_begin>entity 2<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end><edge_begin><edge_end><node_begin>entity 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>\\n<node_begin>entity 1<node_end> <edge_begin><edge_end> <node_begin>entity 3<node_end>', '<node_begin>aggregate 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>aggregate 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end><edge_begin><edge_end><node_begin>service 1<node_end>', '<node_begin>entity 6<node_end><edge_begin><edge_end><node_begin>aggregate 6<node_end>', '<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>core domain<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 4<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The kernel should contain a specific in-depth domain model and a flexible architecture<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The most qualified programmers and specialists should work on the core.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Small in size.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Core is the most valuable part of the model, giving a competitive advantage<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Distillation document<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Flagged Core<node_end><edge_begin><edge_end><node_begin>aggregate 5<node_end> <edge_begin><edge_end> <node_begin>aggregate 6<node_end>', '<node_begin>entity 5<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end><edge_begin><edge_end><node_begin>entity 6<node_end> <edge_begin><edge_end> <node_begin>aggregate 6<node_end>', '<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>core domain<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The kernel should contain a specific in-depth domain model and a flexible architecture<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The most qualified programmers and specialists should work on the core.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Small in size.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Core is the most valuable part of the model, giving a competitive advantage<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Distillation document<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Flagged Core<node_end><edge_begin><edge_end><node_begin>entity 4<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>', '<node_begin>entity 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end><edge_begin><edge_end><node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end>\\n<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>entity 4<node_end>\\n<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>entity 5<node_end>', '<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end>\\n<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>entity 4<node_end><edge_begin><edge_end><node_begin>entity 5<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>entity 5<node_end> <edge_begin><edge_end> <node_begin>entity 6<node_end>', '<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>core domain<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 4<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The most qualified programmers and specialists should work on the core.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Small in size.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Core is the most valuable part of the model, giving a competitive advantage<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Distillation document<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Flagged Core<node_end><edge_begin><edge_end><node_begin>The kernel should contain a specific in-depth domain model and a flexible architecture<node_end> <edge_begin><edge_end> <node_begin>core domain<node_end>', '<node_begin>Flagged Core<node_end><edge_begin><edge_end><node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end>', '<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>core domain<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 4<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The kernel should contain a specific in-depth domain model and a flexible architecture<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The most qualified programmers and specialists should work on the core.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Core is the most valuable part of the model, giving a competitive advantage<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Distillation document<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Flagged Core<node_end><edge_begin><edge_end><node_begin>Small in size.<node_end> <edge_begin><edge_end> <node_begin>core domain<node_end>', '<node_begin>aggregate 5<node_end><edge_begin><edge_end><node_begin>aggregate 6<node_end>', '<node_begin>Distillation document<node_end><edge_begin><edge_end><node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end>', '<node_begin>aggregate 1<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end><edge_begin><edge_end><node_begin>aggregate 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>aggregate 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>\\n<node_begin>aggregate 3<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end>', '<node_begin>entity 4<node_end><edge_begin><edge_end><node_begin>aggregate 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>aggregate 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>\\n<node_begin>aggregate 3<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end>', '<node_begin>aggregate 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end><edge_begin><edge_end><node_begin>service 1<node_end>', '<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end><edge_begin><edge_end><node_begin>aggregate 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>aggregate 1<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end>', '<node_begin>entity 5<node_end> <edge_begin><edge_end> <node_begin>entity 6<node_end><edge_begin><edge_end><node_begin>aggregate 5<node_end> <edge_begin><edge_end> <node_begin>aggregate 6<node_end>', '<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>core domain<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 4<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The kernel should contain a specific in-depth domain model and a flexible architecture<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The most qualified programmers and specialists should work on the core.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Small in size.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Core is the most valuable part of the model, giving a competitive advantage<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Distillation document<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Flagged Core<node_end><edge_begin><edge_end><node_begin>service 1<node_end>', '<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end>\\n<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>entity 5<node_end><edge_begin><edge_end><node_begin>entity 4<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>']\n",
      "Test Texts:  ['<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end><edge_begin><edge_end><node_begin>entity 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>\\n<node_begin>entity 1<node_end> <edge_begin><edge_end> <node_begin>entity 3<node_end>', '<node_begin>The most qualified programmers and specialists should work on the core.<node_end><edge_begin><edge_end><node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end>', '<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>core domain<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 4<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The kernel should contain a specific in-depth domain model and a flexible architecture<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>The most qualified programmers and specialists should work on the core.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 6<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Small in size.<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>entity 3<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Core is the most valuable part of the model, giving a competitive advantage<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Distillation document<node_end>\\n<node_begin>Bounded context 1<node_end> <edge_begin><edge_end> <node_begin>Flagged Core<node_end><edge_begin><edge_end><node_begin>entity 5<node_end> <edge_begin><edge_end> <node_begin>aggregate 5<node_end>\\n<node_begin>entity 5<node_end> <edge_begin><edge_end> <node_begin>entity 6<node_end>', '<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end><edge_begin><edge_end><node_begin>aggregate 2<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>', '<node_begin>entity 1<node_end> <edge_begin><edge_end> <node_begin>entity 3<node_end><edge_begin><edge_end><node_begin>aggregate 1<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>aggregate 1<node_end> <edge_begin><edge_end> <node_begin>service 1<node_end>', '<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>aggregate 3<node_end>\\n<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>entity 4<node_end>\\n<node_begin>entity 3<node_end> <edge_begin><edge_end> <node_begin>entity 5<node_end><edge_begin><edge_end><node_begin>entity 2<node_end> <edge_begin><edge_end> <node_begin>entity 1<node_end>\\n<node_begin>entity 2<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>', '<node_begin>Core is the most valuable part of the model, giving a competitive advantage<node_end><edge_begin><edge_end><node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end>', '<node_begin>Small in size.<node_end><edge_begin><edge_end><node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>aggregate 2<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 1<node_end>\\n<node_begin>core domain<node_end> <edge_begin><edge_end> <node_begin>entity 2<node_end>', '<node_begin>Analysis of requirements to functions and definition of functional architecture<node_end> <edge_begin><edge_end> <node_begin>Requirements manager<node_end>\\n<node_begin>Analysis of requirements to functions and definition of functional architecture<node_end> <edge_begin><edge_end> <node_begin>Functional diagram (grahical)<node_end><edge_begin><edge_end><node_begin>Development of functional requirements (text statements)<node_end> <edge_begin><edge_end> <node_begin>Development of non-functional requirements<node_end>\\n<node_begin>Development of functional requirements (text statements)<node_end> <edge_begin><edge_end> <node_begin>Functional requirements<node_end>', '<node_begin>Stakeholders requirements specification to the product<node_end><edge_begin><edge_end><node_begin>Requirements management (level of system (technical) requirements to the system, its subsystems or components: hardware and software)<node_end> <edge_begin><edge_end> <node_begin>Technical requirements specification to the product<node_end>', '<node_begin>CFO System<node_end> <edge_begin><edge_end> <node_begin>Payment<node_end>\\n<node_begin>CFO System<node_end> <edge_begin><edge_end> <node_begin>Payment Data<node_end>\\n<node_begin>CFO System<node_end> <edge_begin><edge_end> <node_begin>Financial reports<node_end><edge_begin><edge_end><node_begin>Financial Data<node_end>', '<node_begin>CFO System<node_end><edge_begin><edge_end><node_begin>Payment<node_end>', '<node_begin>Notify the concerned parties<node_end><edge_begin><edge_end><node_begin>Validate informations<node_end> <edge_begin><edge_end> <node_begin>Book the place<node_end>', '<node_begin>Quality System<node_end> <edge_begin><edge_end> <node_begin>Accomodation management system<node_end>\\n<node_begin>Quality System<node_end> <edge_begin><edge_end> <node_begin>Human Resourse<node_end><edge_begin><edge_end><node_begin>Host management<node_end> <edge_begin><edge_end> <node_begin>Accomodation management system<node_end>\\n<node_begin>Host management<node_end> <edge_begin><edge_end> <node_begin>CFO System<node_end>\\n<node_begin>Host management<node_end> <edge_begin><edge_end> <node_begin>Quality System<node_end>', '<node_begin>Host management<node_end> <edge_begin><edge_end> <node_begin>Accomodation management system<node_end>\\n<node_begin>Host management<node_end> <edge_begin><edge_end> <node_begin>CFO System<node_end><edge_begin><edge_end><node_begin>Quality System<node_end> <edge_begin><edge_end> <node_begin>Host management<node_end>\\n<node_begin>Quality System<node_end> <edge_begin><edge_end> <node_begin>Accomodation management system<node_end>\\n<node_begin>Quality System<node_end> <edge_begin><edge_end> <node_begin>Human Resourse<node_end>', '<node_begin>Back Office<node_end> <edge_begin><edge_end> <node_begin>Accomodation management system<node_end>\\n<node_begin>Back Office<node_end> <edge_begin><edge_end> <node_begin>Host management<node_end>\\n<node_begin>Back Office<node_end> <edge_begin><edge_end> <node_begin>Legal Department<node_end>\\n<node_begin>Back Office<node_end> <edge_begin><edge_end> <node_begin>Human Resourse<node_end><edge_begin><edge_end><node_begin>CFO System<node_end> <edge_begin><edge_end> <node_begin>Legal Department<node_end>', '<node_begin><node_end><edge_begin><edge_end><node_begin>Notify the concerned parties<node_end> <edge_begin><edge_end> <node_begin>Validate informations<node_end>', '<node_begin>Back Office<node_end> <edge_begin><edge_end> <node_begin>Accomodation management system<node_end>\\n<node_begin>Back Office<node_end> <edge_begin><edge_end> <node_begin>Host management<node_end>\\n<node_begin>Back Office<node_end> <edge_begin><edge_end> <node_begin>Legal Department<node_end>\\n<node_begin>Back Office<node_end> <edge_begin><edge_end> <node_begin>CFO System<node_end><edge_begin><edge_end><node_begin>Human Resourse<node_end> <edge_begin><edge_end> <node_begin>Accomodation management system<node_end>\\n<node_begin>Human Resourse<node_end> <edge_begin><edge_end> <node_begin>Host management<node_end>\\n<node_begin>Human Resourse<node_end> <edge_begin><edge_end> <node_begin>Quality System<node_end>', '<node_begin>Contract Data<node_end><edge_begin><edge_end><node_begin>Contract<node_end> <edge_begin><edge_end> <node_begin>Hosts<node_end>', '<node_begin>Rent demand received<node_end><edge_begin><edge_end><node_begin>Notify the concerned parties<node_end> <edge_begin><edge_end> <node_begin>Validate informations<node_end>']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "data = graph_node_dataset.get_link_prediction_texts(label='type')\n",
    "texts = sum([v for k, v in data.items() if not k.endswith(\"classes\")], [])\n",
    "sentences = [text.split() for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70471"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "model = TfidfVectorizer()\n",
    "model.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = model.transform(texts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse._csr.csr_matrix, True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "type(t), isinstance(t, csr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "isinstance(t, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db6958fabbc491b871472e05f170fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding node graphs:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaefe647c72342458730467e867d0081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating graphs:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AndJunction' 'ApplicationCollaboration' 'ApplicationComponent'\n",
      " 'ApplicationEvent' 'ApplicationFunction' 'ApplicationInteraction'\n",
      " 'ApplicationInterface' 'ApplicationProcess' 'ApplicationService'\n",
      " 'Artifact' 'Assessment' 'BusinessActor' 'BusinessCollaboration'\n",
      " 'BusinessEvent' 'BusinessFunction' 'BusinessInteraction'\n",
      " 'BusinessInterface' 'BusinessObject' 'BusinessProcess' 'BusinessRole'\n",
      " 'BusinessService' 'Capability' 'CommunicationNetwork' 'Constraint'\n",
      " 'Contract' 'CourseOfAction' 'DataObject' 'Deliverable' 'Device'\n",
      " 'DistributionNetwork' 'Driver' 'Equipment' 'Facility' 'Gap' 'Goal'\n",
      " 'Grouping' 'ImplementationEvent' 'Junction' 'Location' 'Material'\n",
      " 'Meaning' 'Node' 'OrJunction' 'Outcome' 'Path' 'Plateau' 'Principle'\n",
      " 'Product' 'Representation' 'Requirement' 'Resource' 'Stakeholder'\n",
      " 'SystemSoftware' 'TechnologyCollaboration' 'TechnologyEvent'\n",
      " 'TechnologyFunction' 'TechnologyInteraction' 'TechnologyInterface'\n",
      " 'TechnologyProcess' 'TechnologyService' 'Value' 'ValueStream'\n",
      " 'WorkPackage' None]\n",
      "Setting num_nodes_ type 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d15df71b7a4cf5811b0adcaa0c53f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating node classes:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63}\n",
      "Test classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63}\n",
      "Number of classes in training set: 64\n",
      "Number of classes in test set: 64\n",
      "['application' 'business' 'implementation_migration' 'motivation' 'other'\n",
      " 'strategy' 'technology' None]\n",
      "Setting num_nodes_ layer 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461555170f684697a337904ed75c06f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating node classes:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Test classes: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Number of classes in training set: 8\n",
      "Number of classes in test set: 8\n",
      "Edge Classes:  ['Access' 'Aggregation' 'Assignment' 'Association' 'Composition' 'Flow'\n",
      " 'Influence' 'Realization' 'Serving' 'Specialization' 'Triggering']\n",
      "Node label: type\n",
      "Train Node classes: {6: 708, 26: 2661, 4: 2366, 7: 1484, 2: 3827, 11: 1376, 8: 1821, 41: 1248, 21: 1632, 40: 138, 35: 2259, 17: 3385, 49: 1308, 60: 187, 3: 251, 20: 1324, 14: 1490, 25: 574, 18: 2667, 12: 199, 9: 880, 61: 152, 47: 486, 28: 427, 10: 566, 51: 461, 43: 370, 50: 195, 23: 229, 38: 171, 30: 416, 46: 789, 62: 316, 19: 1139, 52: 1167, 54: 52, 59: 860, 57: 282, 55: 258, 37: 205, 48: 365, 16: 2113, 34: 662, 15: 157, 13: 480, 22: 280, 24: 112, 5: 86, 0: 64, 44: 132, 58: 146, 1: 161, 31: 102, 29: 36, 42: 63, 53: 159, 32: 84, 45: 163, 27: 135, 39: 41, 36: 39, 63: 87, 33: 87, 56: 26}\n",
      "Test Node classes: {4: 612, 7: 374, 2: 954, 11: 393, 26: 677, 21: 436, 17: 889, 35: 601, 3: 58, 20: 353, 14: 412, 9: 235, 18: 775, 25: 122, 19: 316, 41: 308, 61: 44, 38: 40, 47: 109, 10: 144, 8: 396, 52: 291, 37: 51, 48: 107, 6: 170, 46: 163, 49: 323, 34: 167, 30: 100, 13: 129, 16: 579, 60: 48, 51: 90, 59: 199, 28: 104, 22: 60, 56: 5, 12: 65, 55: 68, 23: 55, 44: 40, 50: 59, 29: 10, 62: 75, 5: 33, 32: 19, 39: 9, 24: 28, 0: 16, 15: 39, 40: 25, 57: 65, 63: 27, 58: 23, 42: 14, 54: 14, 31: 21, 45: 39, 33: 29, 53: 37, 43: 82, 1: 41, 36: 7, 27: 26}\n",
      "Node label: layer\n",
      "Train Node classes: {0: 13365, 1: 15293, 6: 6180, 5: 2553, 3: 5126, 4: 2762, 2: 740, 7: 87}\n",
      "Test Node classes: {0: 3315, 1: 4194, 5: 661, 4: 722, 6: 1508, 3: 1197, 2: 176, 7: 27}\n",
      "Loaded graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c707d063ca41faba6bbf26d2da7b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting node classification data:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data\n",
      "['<node_begin>interface prototype<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 3<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>method 2<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>type:ApplicationFunction method 1<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>clone<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Serving<edge_end> <node_begin>class client<node_end>', '<node_begin>instance A<node_end> <edge_begin>type:Association<edge_end> <node_begin>type:ApplicationComponent subclass prototype A<node_end>', '<node_begin>construct algoritm<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess construct some object<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Realization<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Realization<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Composition<edge_end> <node_begin>type:ApplicationFunction clone instance<node_end>', '<node_begin>clone<node_end>', '<node_begin>method 3<node_end>', '<node_begin>step on new instance<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>step on new instance<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 3<node_end>', '<node_begin>method 3<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>method 3<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationFunction method 3<node_end>', '<node_begin>create subclass proto<node_end> <edge_begin>type:Access<edge_end> <node_begin>type:DataObject instance A<node_end>\\n<node_begin>create subclass proto<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationProcess create client<node_end>', '<node_begin>step on new instance<node_end> <edge_begin>type:Flow<edge_end> <node_begin>method 2<node_end>', '<node_begin>method 1<node_end>']\n",
      "['<node_begin>clone<node_end> <edge_begin>type:Serving<edge_end> <node_begin>get specific result A<node_end>', '<node_begin>get specific result A<node_end>', '<node_begin>class client<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction construct algoritm<node_end>\\n<node_begin>class client<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess create client<node_end>', '<node_begin>clone<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationFunction clone instance<node_end>\\n<node_begin>clone<node_end> <edge_begin>type:Flow<edge_end> <node_begin>clone<node_end>', '<node_begin>method 2<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>method 2<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 2<node_end>', '<node_begin>President/CEO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor COO<node_end>\\n<node_begin>President/CEO<node_end> <edge_begin><edge_end> <node_begin>CTO<node_end>', '<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor human resources<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>compliance<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor business development<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor accounting & finance<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor legal<node_end>', '<node_begin>compliance<node_end>', '<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Product Development/Project Manager<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Infrastructure Engineer<node_end>\\n<node_begin>CTO<node_end> <edge_begin><edge_end> <node_begin>type:BusinessActor Sr. WP developer/architect<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Sr. Blockchain developer<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Sr. hybrid mobile developer<node_end>', '<node_begin>DB<node_end>']\n",
      "46019\n",
      "46019\n",
      "11773\n",
      "11773\n"
     ]
    }
   ],
   "source": [
    "from data_loading.graph_dataset import GraphNodeDataset\n",
    "\n",
    "graph_data_params = dict(\n",
    "    reload=True,\n",
    "    test_ratio=0.2,\n",
    "    distance=1,\n",
    "    random_embed_dim=1,\n",
    "    use_attributes=True,\n",
    "    use_node_types=True,\n",
    "    use_edge_label=True,\n",
    "    use_edge_types=True,\n",
    "    use_special_tokens=True,\n",
    "    # use_embeddings=True,\n",
    "    # embed_model_name='bert-base-cased',\n",
    "    # ckpt='results/eamodelset/lp/10_att_0_nt_0/checkpoint-177600',\n",
    "    node_cls_label='type',\n",
    ")\n",
    "\n",
    "    # graph_data_params = dict(\n",
    "    #     distance=args.distance,\n",
    "    #     reload=args.reload,\n",
    "    #     test_ratio=args.test_ratio,\n",
    "    #     use_attributes=args.use_attributes,\n",
    "    #     use_node_types=args.use_node_types,\n",
    "    #     use_edge_types=args.use_edge_types,\n",
    "    #     use_edge_label=args.use_edge_label,\n",
    "    #     use_special_tokens=args.use_special_tokens,\n",
    "    #     no_labels=args.no_labels,\n",
    "    #     node_cls_label=args.cls_label,\n",
    "    #     use_embeddings=args.use_embeddings,\n",
    "    #     embed_model_name=args.embed_model_name,\n",
    "    #     ckpt=args.ckpt,\n",
    "    # )\n",
    "\n",
    "\n",
    "print(\"Loading graph dataset\")\n",
    "graph_node_dataset = GraphNodeDataset(dataset, **graph_data_params)\n",
    "print(\"Loaded graph dataset\")\n",
    "data = graph_node_dataset.get_node_classification_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46019"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = sum([v for k, v in data.items() if k.startswith('train') and not k.endswith('classes')], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XYZ'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='XYZ')\n",
    "\n",
    "b = B()\n",
    "b.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test = data['train_nodes'], data['test_nodes']\n",
    "y_train, y_test = data['train_node_classes'], data['test_node_classes']\n",
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'), verbose=True)\n",
    "\n",
    "print(\"Fitting SVM classifier\")\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Predicting\")\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Step 1: Train a Word2Vec model\n",
    "sentences = [text.split() for text in data['train_nodes'] + data['test_nodes']]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Step 2: Use the embeddings to transform the dataset\n",
    "def get_embeddings(texts, model):\n",
    "\tembeddings = []\n",
    "\tfor text in texts:\n",
    "\t\twords = text.split()\n",
    "\t\tword_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "\t\tif word_vectors:\n",
    "\t\t\tembeddings.append(np.mean(word_vectors, axis=0))\n",
    "\t\telse:\n",
    "\t\t\tembeddings.append(np.zeros(model.vector_size))\n",
    "\treturn np.array(embeddings)\n",
    "\n",
    "X_train_embeddings = get_embeddings(data['train_nodes'], word2vec_model)\n",
    "X_test_embeddings = get_embeddings(data['test_nodes'], word2vec_model)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(data['train_node_classes'])\n",
    "y_test = label_encoder.transform(data['test_node_classes'])\n",
    "\n",
    "# Step 3: Train an SVM classifier using the embeddings\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train_embeddings, y_train)\n",
    "y_pred_svm = svm_classifier.predict(X_test_embeddings)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Step 4: Train a neural network classifier using the embeddings\n",
    "class SimpleNN(nn.Module):\n",
    "\tdef __init__(self, input_dim, output_dim):\n",
    "\t\tsuper(SimpleNN, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(input_dim, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, output_dim)\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = torch.relu(self.fc1(x))\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn x\n",
    "\n",
    "input_dim = X_train_embeddings.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = SimpleNN(input_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_embeddings, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_embeddings, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\tmodel.train()\n",
    "\tfor X_batch, y_batch in train_loader:\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(X_batch)\n",
    "\t\tloss = criterion(outputs, y_batch)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\tprint(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluate the neural network\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\toutputs = model(X_test_tensor)\n",
    "\t_, y_pred_nn = torch.max(outputs, 1)\n",
    "\ty_pred_nn = y_pred_nn.numpy()\n",
    "\tprint(\"Neural Network Classification Report:\")\n",
    "\tprint(classification_report(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import W2V_CONFIG\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "from typing import List, Union\n",
    "from embeddings.common import Embedder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class TFIDFEmbedder(Embedder):\n",
    "    def __init__(self, texts: List[str]):\n",
    "        print(\"TFIDFEmbedder: Training TF-IDF model\")\n",
    "        self.model = TfidfVectorizer()\n",
    "        self.model.fit(texts)\n",
    "        print(\"TFIDFEmbedder: Model trained\")\n",
    "\n",
    "    @property\n",
    "    def embedding_dim(self) -> int:\n",
    "        return len(self.model.get_feature_names_out())\n",
    "    \n",
    "    def embed(self, text: Union[str, List[str]]):\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        return torch.tensor(self.model.transform(text).toarray()[0])\n",
    "\n",
    "class Word2VecEmbedder(Embedder):\n",
    "    def __init__(self, texts: List[str]):\n",
    "        print(\"Word2VecEmbedder: Training Word2Vec model\")\n",
    "        self.model = Word2Vec(texts, **W2V_CONFIG)\n",
    "        print(\"Word2VecEmbedder: Word2Vec model trained\")\n",
    "\n",
    "    @property\n",
    "    def embedding_dim(self) -> int:\n",
    "        return self.model.vector_size\n",
    "    \n",
    "    def embed(self, text: Union[str, List[str]]):\n",
    "        if isinstance(text, str):\n",
    "            text = text.split()\n",
    "        word_vectors = [self.model.wv[word] for word in text if word in self.model.wv]\n",
    "        if word_vectors:\n",
    "            return torch.tensor(word_vectors).mean(dim=0)\n",
    "        else:\n",
    "            return torch.zeros(self.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embedder = Word2VecEmbedder(texts)\n",
    "tfidf_embedder = TFIDFEmbedder(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_node(1, label='A')\n",
    "G.add_node(2, label='B')\n",
    "G.add_node(3, label='C')\n",
    "G.add_node(4, label='D')\n",
    "G.add_node(5, label='E')\n",
    "G.add_node(6, label='F')\n",
    "\n",
    "G.add_edge(1, 2, label='1')\n",
    "G.add_edge(1, 3, label='2')\n",
    "G.add_edge(1, 6, label='5')\n",
    "G.add_edge(2, 3, label='6')\n",
    "G.add_edge(2, 5, label='8')\n",
    "G.add_edge(2, 6, label='9')\n",
    "G.add_edge(3, 4, label='10')\n",
    "G.add_edge(3, 5, label='11')\n",
    "G.add_edge(4, 5, label='13')\n",
    "G.add_edge(4, 6, label='14')\n",
    "G.add_edge(5, 6, label='15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 3, 5, 4] [1, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NodeDataView({1: {'label': 'A', 'masked': 1}, 2: {'label': 'B', 'masked': 1}, 3: {'label': 'C', 'masked': 0}, 4: {'label': 'D', 'masked': 0}, 5: {'label': 'E', 'masked': 0}, 6: {'label': 'F', 'masked': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_nodes, test_nodes = train_test_split(\n",
    "\tlist(G.nodes), \n",
    "\ttest_size=0.2, \n",
    "\tshuffle=True, \n",
    "\trandom_state=42\n",
    ")\n",
    "\n",
    "print(train_nodes, test_nodes)\n",
    "nx.set_node_attributes(G, {node: 0 for node in train_nodes}, 'masked')\n",
    "nx.set_node_attributes(G, {node: 1 for node in test_nodes}, 'masked')\n",
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeDataView([(1, 2, {'label': '1', 'masked': False}), (1, 3, {'label': '2', 'masked': False}), (1, 6, {'label': '5', 'masked': False}), (2, 3, {'label': '6', 'masked': False}), (2, 5, {'label': '8', 'masked': False}), (2, 6, {'label': '9', 'masked': True}), (3, 4, {'label': '10', 'masked': False}), (3, 5, {'label': '11', 'masked': True}), (4, 5, {'label': '13', 'masked': False}), (4, 6, {'label': '14', 'masked': False}), (5, 6, {'label': '15', 'masked': False})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import torch\n",
    "from data_loading.data import GraphData\n",
    "import numpy as np\n",
    "\n",
    "edge_index = np.array(G.edges()).T\n",
    "transform = RandomLinkSplit(\n",
    "\tnum_val=0, \n",
    "\tnum_test=0.2, \n",
    "\tadd_negative_train_samples=True,\n",
    "\tneg_sampling_ratio=1,\n",
    "\tsplit_labels=True\n",
    ")\n",
    "\n",
    "train_data, _, test_data = transform(GraphData(\n",
    "\tedge_index=torch.tensor(edge_index), \n",
    "\tnum_nodes=G.number_of_nodes()\n",
    "))\n",
    "nx.set_edge_attributes(G, {tuple(edge): False for edge in train_data.pos_edge_label_index.T.tolist()}, 'masked')\n",
    "nx.set_edge_attributes(G, {tuple(edge): True for edge in test_data.pos_edge_label_index.T.tolist()}, 'masked')\n",
    "G.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
