{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "datasets_dir = 'datasets'\n",
    "ecore_json_path = os.path.join(datasets_dir, 'ecore_555/ecore_555.jsonl')\n",
    "mar_json_path = os.path.join(datasets_dir, 'mar-ecore-github/ecore-github.jsonl')\n",
    "modelsets_uml_json_path = os.path.join(datasets_dir, 'modelset/uml.jsonl')\n",
    "modelsets_ecore_json_path = os.path.join(datasets_dir, 'modelset/ecore.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ecore from pickle\n",
      "Loaded ecore from pickle\n",
      "Graphs: 548\n",
      "Loading mar from pickle\n",
      "Loaded mar from pickle\n",
      "Graphs: 18110\n",
      "Loading modelsets_uml from pickle\n",
      "Loaded modelsets_uml from pickle\n",
      "Graphs: 3720\n",
      "Loading modelsets_ecore from pickle\n",
      "Loaded modelsets_ecore from pickle\n",
      "Graphs: 4127\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "class GenericGraph(nx.DiGraph):\n",
    "    def __init__(self, json_obj):\n",
    "        super().__init__()\n",
    "        self.graph_id = json_obj.get('ids', None)\n",
    "        self.graph_type = json_obj.get('model_type', None)\n",
    "        self.label = json_obj.get('labels', None)\n",
    "        self.is_duplicated = json_obj.get('is_duplicated', None)\n",
    "        self.directed = json_obj.get('directed', None)\n",
    "        self.create_graph(json_obj)\n",
    "\n",
    "    def create_graph(self, json_obj):\n",
    "        graph = json.loads(json_obj['graph'])\n",
    "        nodes = graph['nodes']\n",
    "        edges = graph['links']\n",
    "        for node in nodes:\n",
    "            self.add_node(node['id'], **node)\n",
    "        for edge in edges:\n",
    "            self.add_edge(edge['source'], edge['target'], **edge)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Graph({self.graph_id}, nodes={self.number_of_nodes()}, edges={self.number_of_edges()})'\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(\n",
    "            self, \n",
    "            file_name, \n",
    "            name, \n",
    "            dataset_dir = datasets_dir,\n",
    "            save_dir = 'datasets/pickles',\n",
    "            reload=False\n",
    "        ):\n",
    "        self.name = name\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        dataset_exists = os.path.exists(os.path.join(save_dir, f'{name}.pkl'))\n",
    "        if reload or not dataset_exists:\n",
    "            json_objects = json.load(open(os.path.join(dataset_dir, file_name)))\n",
    "            self.graphs = [GenericGraph(g) for g in tqdm(json_objects, desc=f'Loading {name.title()}')]\n",
    "            self.save()\n",
    "        \n",
    "        else:\n",
    "            self.load()\n",
    "\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "        self.graphs = self.dedup()\n",
    "\n",
    "    def dedup(self):\n",
    "        return list({str(g.edges): g for g in self.graphs}.values())\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Dataset({self.name}, graphs={len(self.graphs)})'\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.graphs[key]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.graphs)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def save(self):\n",
    "        print(f'Saving {self.name} to pickle')\n",
    "        with open(os.path.join(self.save_dir, f'{self.name}.pkl'), 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        print(f'Saved {self.name} to pickle')\n",
    "\n",
    "    def load(self):\n",
    "        print(f'Loading {self.name} from pickle')\n",
    "        with open(os.path.join(self.save_dir, f'{self.name}.pkl'), 'rb') as f:\n",
    "            self = pickle.load(f)\n",
    "        \n",
    "        print(f'Loaded {self.name} from pickle')\n",
    "        print(f'Graphs: {len(self.graphs)}')\n",
    "        \n",
    "\n",
    "reload = False\n",
    "ecore = Dataset('ecore_555/ecore_555.jsonl', 'ecore', reload=reload)\n",
    "mar = Dataset('mar-ecore-github/ecore-github.jsonl', 'mar', reload=reload)\n",
    "modelsets_uml = Dataset('modelset/uml.jsonl', 'modelsets_uml', reload=reload)\n",
    "modelsets_ecore = Dataset('modelset/ecore.jsonl', 'modelsets_ecore', reload=reload)\n",
    "\n",
    "datasets = {\n",
    "    'ecore': ecore,\n",
    "    'mar': mar,\n",
    "    'modelsets_uml': modelsets_uml,\n",
    "    'modelsets_ecore': modelsets_ecore\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
