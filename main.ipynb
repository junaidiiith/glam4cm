{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading eamodelset from pickle\n",
      "Loaded eamodelset with 558 graphs\n",
      "Loaded eamodelset with 558 graphs\n",
      "Graphs: 558\n"
     ]
    }
   ],
   "source": [
    "from utils import set_seed\n",
    "from data_loading.models_dataset import ArchiMateModelDataset, EcoreModelDataset\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "config_params = dict(\n",
    "    # reload=True,\n",
    "    min_enr = -1,\n",
    "    min_edges = 10,\n",
    "    language = 'en',\n",
    ")\n",
    "dataset_name = 'eamodelset'\n",
    "\n",
    "dataset = ArchiMateModelDataset(dataset_name, **config_params)\n",
    "# dataset = EcoreModelDataset('modelset', **config_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16169da2893d469c9707b33fecbfa0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding edge graphs:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a12be89085427fa682f0c7e0f8368d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating graphs:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AndJunction' 'ApplicationCollaboration' 'ApplicationComponent'\n",
      " 'ApplicationEvent' 'ApplicationFunction' 'ApplicationInteraction'\n",
      " 'ApplicationInterface' 'ApplicationProcess' 'ApplicationService'\n",
      " 'Artifact' 'Assessment' 'BusinessActor' 'BusinessCollaboration'\n",
      " 'BusinessEvent' 'BusinessFunction' 'BusinessInteraction'\n",
      " 'BusinessInterface' 'BusinessObject' 'BusinessProcess' 'BusinessRole'\n",
      " 'BusinessService' 'Capability' 'CommunicationNetwork' 'Constraint'\n",
      " 'Contract' 'CourseOfAction' 'DataObject' 'Deliverable' 'Device'\n",
      " 'DistributionNetwork' 'Driver' 'Equipment' 'Facility' 'Gap' 'Goal'\n",
      " 'Grouping' 'ImplementationEvent' 'Junction' 'Location' 'Material'\n",
      " 'Meaning' 'Node' 'OrJunction' 'Outcome' 'Path' 'Plateau' 'Principle'\n",
      " 'Product' 'Representation' 'Requirement' 'Resource' 'Stakeholder'\n",
      " 'SystemSoftware' 'TechnologyCollaboration' 'TechnologyEvent'\n",
      " 'TechnologyFunction' 'TechnologyInteraction' 'TechnologyInterface'\n",
      " 'TechnologyProcess' 'TechnologyService' 'Value' 'ValueStream'\n",
      " 'WorkPackage' None]\n",
      "Setting num_nodes_ type 63\n",
      "['application' 'business' 'implementation_migration' 'motivation' 'other'\n",
      " 'strategy' 'technology' None]\n",
      "Setting num_nodes_ layer 7\n",
      "Edge Classes:  ['Access' 'Aggregation' 'Assignment' 'Association' 'Composition' 'Flow'\n",
      " 'Influence' 'Realization' 'Serving' 'Specialization' 'Triggering']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a11bc2f772646869255b8f7d54d7d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating edge classes:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "Test classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "Number of classes in training set: 11\n",
      "Number of classes in test set: 11\n",
      "Train edge classes: {4: 12829, 7: 7122, 8: 5405, 2: 5711, 3: 7522, 5: 4441, 1: 3517, 0: 3948, 10: 4429, 9: 1192, 6: 686}\n",
      "Test edge classes: {7: 1751, 4: 3063, 3: 1827, 5: 1021, 1: 881, 0: 1019, 9: 314, 2: 1450, 10: 1068, 6: 177, 8: 1352}\n",
      "Loaded graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81801ad4506c4050993827251d419b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting edge_cls data:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Texts:  ['<node_begin>PASS<node_end><edge_begin><edge_end><node_begin>European Front office<node_end>', '<node_begin>Merchant portal data exposure<node_end><edge_begin><edge_end><node_begin>MP Reconciliation status preparation<node_end>', '<node_begin>Download Acquiring Transaction of a merchant user<node_end><edge_begin><edge_end><node_begin>Send Acq data access request to data storage location<node_end>', '<node_begin>c IAM<node_end><edge_begin><edge_end><node_begin>Broadcast Merchant data to platforms<node_end>', '<node_begin>Create contract hierarchies<node_end><edge_begin><edge_end><node_begin>Create PASS merchant hierarchy<node_end>', '<node_begin>Activate existing merchant for reconciliation<node_end><edge_begin><edge_end><node_begin>Update contract hierarchies for reconciliation<node_end>', '<node_begin>c IAM<node_end><edge_begin><edge_end><node_begin>Enable Acceptance and Acquiring data access in Acceptance applications<node_end>', '<node_begin>Transaction report (Acc & Acquiring)<node_end><edge_begin><edge_end><node_begin>Reconciliation engine<node_end>', '<node_begin>Merchant Portal<node_end><edge_begin><edge_end><node_begin>e Com Acc (WLOP)<node_end>', '<node_begin>Data Platform<node_end><edge_begin><edge_end><node_begin>Ingestion<node_end>', '<node_begin>Merchant Provisioning<node_end><edge_begin><edge_end><node_begin>Broadcast Merchant data to platforms<node_end>', '<node_begin>Reconcile e Com Acceptance and Acquiring transactions<node_end><edge_begin><edge_end><node_begin>Decide on reconciliation status<node_end>', '<node_begin>Data Platform<node_end><edge_begin><edge_end><node_begin>Merchant portal data exposure<node_end>', '<node_begin>Merchant portal data exposure<node_end><edge_begin><edge_end><node_begin>MP e Com data extraction<node_end>', '<node_begin>Merchant users boarding<node_end><edge_begin><edge_end><node_begin>Activate existing merchant for reconciliation<node_end>', '<node_begin>Ingestion<node_end><edge_begin><edge_end><node_begin>e P2 data ingestion<node_end>', '<node_begin>Merchant Portal<node_end><edge_begin><edge_end><node_begin>Transaction report (Acc & Acquiring)<node_end>', '<node_begin>Reconcile e Com Acceptance and Acquiring transactions<node_end><edge_begin><edge_end><node_begin>Compare Acquiring to acceptance transaction lifecycle status<node_end>', '<node_begin>MEPO<node_end><edge_begin><edge_end><node_begin>Create contract hierarchies<node_end>', '<node_begin>PASS<node_end><edge_begin><edge_end><node_begin>Settlements<node_end>']\n",
      "Test Texts:  ['<node_begin>MEON<node_end><edge_begin><edge_end><node_begin>Create contract hierarchies<node_end>', '<node_begin>Download Acquiring Transaction of a merchant user<node_end><edge_begin><edge_end><node_begin>Store Acquiring transaction data<node_end>', '<node_begin>MEON<node_end><edge_begin><edge_end><node_begin>Broadcast Merchant data to platforms<node_end>', '<node_begin>WLOP<node_end><edge_begin><edge_end><node_begin>WLOP Transaction d B<node_end>', '<node_begin>Ingestion<node_end><edge_begin><edge_end><node_begin>WLOP data ingestion<node_end>', '<node_begin>Merchant portal data exposure<node_end><edge_begin><edge_end><node_begin>MP Acc data extraction<node_end>', '<node_begin>Merchant portal data exposure<node_end><edge_begin><edge_end><node_begin>MP in Store acc data extraction<node_end>', '<node_begin>Update contract hierarchies for reconciliation<node_end><edge_begin><edge_end><node_begin>Create a common merchant ID<node_end>', '<node_begin>Merchant portal data exposure<node_end><edge_begin><edge_end><node_begin>MP PASS data extraction<node_end>', '<node_begin>Activate existing merchant for reconciliation<node_end><edge_begin><edge_end><node_begin>Create a common merchant ID<node_end>', '<node_begin>entity 6<node_end><edge_begin><edge_end><node_begin>aggregate 6<node_end>', '<node_begin>aggregate 5<node_end><edge_begin><edge_end><node_begin>aggregate 6<node_end>', '<node_begin>Bounded context 1<node_end><edge_begin><edge_end><node_begin>service 1<node_end>', '<node_begin>entity 3<node_end><edge_begin><edge_end><node_begin>entity 2<node_end>', '<node_begin>entity 3<node_end><edge_begin><edge_end><node_begin>aggregate 3<node_end>', '<node_begin>entity 3<node_end><edge_begin><edge_end><node_begin>entity 5<node_end>', '<node_begin>aggregate 3<node_end><edge_begin><edge_end><node_begin>service 1<node_end>', '<node_begin>Bounded context 1<node_end><edge_begin><edge_end><node_begin>core domain (subdomain)<node_end>', '<node_begin>Bounded context 1<node_end><edge_begin><edge_end><node_begin>team 2 (low priority)<node_end>', '<node_begin>Claim Management Services<node_end><edge_begin><edge_end><node_begin>Claim received<node_end>']\n"
     ]
    }
   ],
   "source": [
    "from data_loading.graph_dataset import GraphEdgeDataset\n",
    "import utils\n",
    "\n",
    "utils.set_seed(42)\n",
    "\n",
    "graph_data_params = dict(\n",
    "    reload=True,\n",
    "    test_ratio=0.2,\n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1,\n",
    "    distance=0,\n",
    "    random_embed_dim=1,\n",
    "    use_attributes=True,\n",
    "    use_edge_label=True,\n",
    "    use_edge_types=True,\n",
    "    use_node_types=True,\n",
    "    use_special_tokens=True,\n",
    "    # use_embeddings=True,\n",
    "    # embed_model_name='bert-base-cased',\n",
    "    # ckpt='results/eamodelset/lp/10_att_0_nt_0/checkpoint-177600',\n",
    "    limit = -1,\n",
    ")\n",
    "\n",
    "print(\"Loading graph dataset\")\n",
    "graph_edge_dataset = GraphEdgeDataset(dataset, **graph_data_params)\n",
    "print(\"Loaded graph dataset\")\n",
    "\n",
    "texts = graph_edge_dataset.get_link_prediction_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e49aea61f944285b2ad6e7a11b8fc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding node graphs:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76288bddfb3c4549aa4a52bddaa4ab39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating graphs:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AndJunction' 'ApplicationCollaboration' 'ApplicationComponent'\n",
      " 'ApplicationEvent' 'ApplicationFunction' 'ApplicationInteraction'\n",
      " 'ApplicationInterface' 'ApplicationProcess' 'ApplicationService'\n",
      " 'Artifact' 'Assessment' 'BusinessActor' 'BusinessCollaboration'\n",
      " 'BusinessEvent' 'BusinessFunction' 'BusinessInteraction'\n",
      " 'BusinessInterface' 'BusinessObject' 'BusinessProcess' 'BusinessRole'\n",
      " 'BusinessService' 'Capability' 'CommunicationNetwork' 'Constraint'\n",
      " 'Contract' 'CourseOfAction' 'DataObject' 'Deliverable' 'Device'\n",
      " 'DistributionNetwork' 'Driver' 'Equipment' 'Facility' 'Gap' 'Goal'\n",
      " 'Grouping' 'ImplementationEvent' 'Junction' 'Location' 'Material'\n",
      " 'Meaning' 'Node' 'OrJunction' 'Outcome' 'Path' 'Plateau' 'Principle'\n",
      " 'Product' 'Representation' 'Requirement' 'Resource' 'Stakeholder'\n",
      " 'SystemSoftware' 'TechnologyCollaboration' 'TechnologyEvent'\n",
      " 'TechnologyFunction' 'TechnologyInteraction' 'TechnologyInterface'\n",
      " 'TechnologyProcess' 'TechnologyService' 'Value' 'ValueStream'\n",
      " 'WorkPackage' None]\n",
      "Setting num_nodes_ type 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a57953de7b4cb4a234170531785878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating node classes:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63}\n",
      "Test classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63}\n",
      "Number of classes in training set: 64\n",
      "Number of classes in test set: 64\n",
      "['application' 'business' 'implementation_migration' 'motivation' 'other'\n",
      " 'strategy' 'technology' None]\n",
      "Setting num_nodes_ layer 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7eda19a18d444b955eba834f8ccc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating node classes:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Test classes: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Number of classes in training set: 8\n",
      "Number of classes in test set: 8\n",
      "Edge Classes:  ['Access' 'Aggregation' 'Assignment' 'Association' 'Composition' 'Flow'\n",
      " 'Influence' 'Realization' 'Serving' 'Specialization' 'Triggering']\n",
      "Node label: type\n",
      "Train Node classes: {6: 708, 26: 2661, 4: 2366, 7: 1484, 2: 3827, 11: 1376, 8: 1821, 41: 1248, 21: 1632, 40: 138, 35: 2259, 17: 3385, 49: 1308, 60: 187, 3: 251, 20: 1324, 14: 1490, 25: 574, 18: 2667, 12: 199, 9: 880, 61: 152, 47: 486, 28: 427, 10: 566, 51: 461, 43: 370, 50: 195, 23: 229, 38: 171, 30: 416, 46: 789, 62: 316, 19: 1139, 52: 1167, 54: 52, 59: 860, 57: 282, 55: 258, 37: 205, 48: 365, 16: 2113, 34: 662, 15: 157, 13: 480, 22: 280, 24: 112, 5: 86, 0: 64, 44: 132, 58: 146, 1: 161, 31: 102, 29: 36, 42: 63, 53: 159, 32: 84, 45: 163, 27: 135, 39: 41, 36: 39, 63: 87, 33: 87, 56: 26}\n",
      "Test Node classes: {4: 612, 7: 374, 2: 954, 11: 393, 26: 677, 21: 436, 17: 889, 35: 601, 3: 58, 20: 353, 14: 412, 9: 235, 18: 775, 25: 122, 19: 316, 41: 308, 61: 44, 38: 40, 47: 109, 10: 144, 8: 396, 52: 291, 37: 51, 48: 107, 6: 170, 46: 163, 49: 323, 34: 167, 30: 100, 13: 129, 16: 579, 60: 48, 51: 90, 59: 199, 28: 104, 22: 60, 56: 5, 12: 65, 55: 68, 23: 55, 44: 40, 50: 59, 29: 10, 62: 75, 5: 33, 32: 19, 39: 9, 24: 28, 0: 16, 15: 39, 40: 25, 57: 65, 63: 27, 58: 23, 42: 14, 54: 14, 31: 21, 45: 39, 33: 29, 53: 37, 43: 82, 1: 41, 36: 7, 27: 26}\n",
      "Node label: layer\n",
      "Train Node classes: {0: 13365, 1: 15293, 6: 6180, 5: 2553, 3: 5126, 4: 2762, 2: 740, 7: 87}\n",
      "Test Node classes: {0: 3315, 1: 4194, 5: 661, 4: 722, 6: 1508, 3: 1197, 2: 176, 7: 27}\n",
      "Loaded graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41eec66a2d4439cb1955c49f0ba4c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting node classification data:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data\n",
      "['<node_begin>interface prototype<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 3<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>method 2<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>type:ApplicationFunction method 1<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>clone<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Serving<edge_end> <node_begin>class client<node_end>', '<node_begin>instance A<node_end> <edge_begin>type:Association<edge_end> <node_begin>type:ApplicationComponent subclass prototype A<node_end>', '<node_begin>construct algoritm<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess construct some object<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Realization<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Realization<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Composition<edge_end> <node_begin>type:ApplicationFunction clone instance<node_end>', '<node_begin>clone<node_end>', '<node_begin>method 3<node_end>', '<node_begin>step on new instance<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>step on new instance<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 3<node_end>', '<node_begin>method 3<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>method 3<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationFunction method 3<node_end>', '<node_begin>create subclass proto<node_end> <edge_begin>type:Access<edge_end> <node_begin>type:DataObject instance A<node_end>\\n<node_begin>create subclass proto<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationProcess create client<node_end>', '<node_begin>step on new instance<node_end> <edge_begin>type:Flow<edge_end> <node_begin>method 2<node_end>', '<node_begin>method 1<node_end>']\n",
      "['<node_begin>clone<node_end> <edge_begin>type:Serving<edge_end> <node_begin>get specific result A<node_end>', '<node_begin>get specific result A<node_end>', '<node_begin>class client<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction construct algoritm<node_end>\\n<node_begin>class client<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess create client<node_end>', '<node_begin>clone<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationFunction clone instance<node_end>\\n<node_begin>clone<node_end> <edge_begin>type:Flow<edge_end> <node_begin>clone<node_end>', '<node_begin>method 2<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>method 2<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 2<node_end>', '<node_begin>President/CEO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor COO<node_end>\\n<node_begin>President/CEO<node_end> <edge_begin><edge_end> <node_begin>CTO<node_end>', '<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor human resources<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>compliance<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor business development<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor accounting & finance<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor legal<node_end>', '<node_begin>compliance<node_end>', '<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Product Development/Project Manager<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Infrastructure Engineer<node_end>\\n<node_begin>CTO<node_end> <edge_begin><edge_end> <node_begin>type:BusinessActor Sr. WP developer/architect<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Sr. Blockchain developer<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Sr. hybrid mobile developer<node_end>', '<node_begin>DB<node_end>']\n",
      "46019\n",
      "46019\n",
      "11773\n",
      "11773\n"
     ]
    }
   ],
   "source": [
    "from data_loading.graph_dataset import GraphNodeDataset\n",
    "\n",
    "graph_data_params = dict(\n",
    "    reload=True,\n",
    "    test_ratio=0.2,\n",
    "    distance=1,\n",
    "    random_embed_dim=1,\n",
    "    use_attributes=True,\n",
    "    use_node_types=True,\n",
    "    use_edge_label=True,\n",
    "    use_edge_types=True,\n",
    "    use_special_tokens=True,\n",
    "    # use_embeddings=True,\n",
    "    # embed_model_name='bert-base-cased',\n",
    "    # ckpt='results/eamodelset/lp/10_att_0_nt_0/checkpoint-177600',\n",
    "    node_cls_label='type',\n",
    ")\n",
    "\n",
    "    # graph_data_params = dict(\n",
    "    #     distance=args.distance,\n",
    "    #     reload=args.reload,\n",
    "    #     test_ratio=args.test_ratio,\n",
    "    #     use_attributes=args.use_attributes,\n",
    "    #     use_node_types=args.use_node_types,\n",
    "    #     use_edge_types=args.use_edge_types,\n",
    "    #     use_edge_label=args.use_edge_label,\n",
    "    #     use_special_tokens=args.use_special_tokens,\n",
    "    #     no_labels=args.no_labels,\n",
    "    #     node_cls_label=args.cls_label,\n",
    "    #     use_embeddings=args.use_embeddings,\n",
    "    #     embed_model_name=args.embed_model_name,\n",
    "    #     ckpt=args.ckpt,\n",
    "    # )\n",
    "\n",
    "\n",
    "print(\"Loading graph dataset\")\n",
    "graph_node_dataset = GraphNodeDataset(dataset, **graph_data_params)\n",
    "print(\"Loaded graph dataset\")\n",
    "data = graph_node_dataset.get_node_classification_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for bert-base-uncased\n",
      "Getting node classification data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6554af00a543a69f10b7f22ae90dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting node classification data:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data\n",
      "['<node_begin>interface prototype<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 3<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>method 2<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>type:ApplicationFunction method 1<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>clone<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Serving<edge_end> <node_begin>class client<node_end>', '<node_begin>instance A<node_end> <edge_begin>type:Association<edge_end> <node_begin>type:ApplicationComponent subclass prototype A<node_end>', '<node_begin>construct algoritm<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess construct some object<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Realization<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Realization<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Composition<edge_end> <node_begin>type:ApplicationFunction clone instance<node_end>', '<node_begin>clone<node_end>', '<node_begin>method 3<node_end>', '<node_begin>step on new instance<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>step on new instance<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 3<node_end>', '<node_begin>method 3<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>method 3<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationFunction method 3<node_end>', '<node_begin>create subclass proto<node_end> <edge_begin>type:Access<edge_end> <node_begin>type:DataObject instance A<node_end>\\n<node_begin>create subclass proto<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationProcess create client<node_end>', '<node_begin>step on new instance<node_end> <edge_begin>type:Flow<edge_end> <node_begin>method 2<node_end>', '<node_begin>method 1<node_end>']\n",
      "['<node_begin>clone<node_end> <edge_begin>type:Serving<edge_end> <node_begin>get specific result A<node_end>', '<node_begin>get specific result A<node_end>', '<node_begin>class client<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction construct algoritm<node_end>\\n<node_begin>class client<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess create client<node_end>', '<node_begin>clone<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationFunction clone instance<node_end>\\n<node_begin>clone<node_end> <edge_begin>type:Flow<edge_end> <node_begin>clone<node_end>', '<node_begin>method 2<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>method 2<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 2<node_end>', '<node_begin>President/CEO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor COO<node_end>\\n<node_begin>President/CEO<node_end> <edge_begin><edge_end> <node_begin>CTO<node_end>', '<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor human resources<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>compliance<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor business development<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor accounting & finance<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor legal<node_end>', '<node_begin>compliance<node_end>', '<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Product Development/Project Manager<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Infrastructure Engineer<node_end>\\n<node_begin>CTO<node_end> <edge_begin><edge_end> <node_begin>type:BusinessActor Sr. WP developer/architect<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Sr. Blockchain developer<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Sr. hybrid mobile developer<node_end>', '<node_begin>DB<node_end>']\n",
      "46019\n",
      "46019\n",
      "11773\n",
      "11773\n",
      "Tokenized data\n"
     ]
    }
   ],
   "source": [
    "from tokenization.utils import get_tokenizer\n",
    "\n",
    "\n",
    "tokenizer = get_tokenizer('bert-base-uncased', use_special_tokens=True)\n",
    "\n",
    "print(\"Getting node classification data\")\n",
    "bert_dataset = graph_node_dataset.get_node_classification_lm_data(\n",
    "\tlabel='type',\n",
    "\ttokenizer=tokenizer,\n",
    "\tdistance=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\t'bert-base-uncased', \n",
    "\tnum_labels=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = getattr(graph_node_dataset, f\"num_nodes_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30526, 63)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer), num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0:1292: indexSelectLargeIndex: block: [53,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex,0], thread: [33,0,0: block: [53,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41: block: [53,0,0], thread: [37,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize: block: [41,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize: indexSelectLargeIndex: block: [53,0,0], thread: [40` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu,0,0], thread: [40,0,0:1292: indexSelectLargeIndex: block: [53,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex,0,0], thread: [42,0,0: block: [41,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: indexSelectLargeIndex: block: [41,0,0], thread: [42: block: [53,0,0], thread: [43,0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      ",0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [43,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [45,0,0: indexSelectLargeIndex: block: [41,0,0], thread: [44] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu: block: [53,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      ":1292: indexSelectLargeIndex: block: [41,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [49,0` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0,0,0], thread: [48,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [49,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      ":1292: indexSelectLargeIndex: block: [53,0,0../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      ":1292: indexSelectLargeIndex: block: [41,0../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [51,0,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [52` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [58,0: indexSelectLargeIndex: block: [53,0,0], thread: [53,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [41../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex,0,0], thread: [61,0,0: block: [53,0,0], thread: [55,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0: block: [41,0,0], thread: [62,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0:1292: indexSelectLargeIndex: block: [41,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [53,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1695, in forward\n    outputs = self.bert(\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1077, in forward\n    embedding_output = self.embeddings(\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 213, in forward\n    embeddings = inputs_embeds + token_type_embeddings\nRuntimeError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 31\u001b[0m\n\u001b[1;32m      8\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      9\u001b[0m \toutput_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m \tnum_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \tfp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     25\u001b[0m \tmodel\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     26\u001b[0m \targs\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     27\u001b[0m \ttrain_dataset\u001b[38;5;241m=\u001b[39mbert_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     28\u001b[0m \teval_dataset\u001b[38;5;241m=\u001b[39mbert_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/trainer.py:3307\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3306\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3307\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3309\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3311\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/trainer.py:3338\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3337\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3338\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3339\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3340\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:110\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    108\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 110\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1695, in forward\n    outputs = self.bert(\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1077, in forward\n    embedding_output = self.embeddings(\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/sali/Miniconda/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 213, in forward\n    embeddings = inputs_embeds + token_type_embeddings\nRuntimeError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "num_labels = 57\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\t'bert-base-uncased', \n",
    "\tnum_labels=num_labels\n",
    ")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir='tmp',\n",
    "\tnum_train_epochs=2,\n",
    "\tper_device_train_batch_size=64,\n",
    "\tper_device_eval_batch_size=128,\n",
    "\tweight_decay=0.01,\n",
    "\tlogging_dir='tmp',\n",
    "\tlogging_steps=200,\n",
    "\teval_strategy='steps',\n",
    "\teval_steps=200,\n",
    "\tsave_steps=200,\n",
    "\tsave_total_limit=2,\n",
    "\tload_best_model_at_end=True,\n",
    "\tfp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\tmodel=model,\n",
    "\targs=training_args,\n",
    "\ttrain_dataset=bert_dataset['train'],\n",
    "\teval_dataset=bert_dataset['test']\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_node(1, label='A')\n",
    "G.add_node(2, label='B')\n",
    "G.add_node(3, label='C')\n",
    "G.add_node(4, label='D')\n",
    "G.add_node(5, label='E')\n",
    "G.add_node(6, label='F')\n",
    "\n",
    "G.add_edge(1, 2, label='1')\n",
    "G.add_edge(1, 3, label='2')\n",
    "G.add_edge(1, 6, label='5')\n",
    "G.add_edge(2, 3, label='6')\n",
    "G.add_edge(2, 5, label='8')\n",
    "G.add_edge(2, 6, label='9')\n",
    "G.add_edge(3, 4, label='10')\n",
    "G.add_edge(3, 5, label='11')\n",
    "G.add_edge(4, 5, label='13')\n",
    "G.add_edge(4, 6, label='14')\n",
    "G.add_edge(5, 6, label='15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 3, 5, 4] [1, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NodeDataView({1: {'label': 'A', 'masked': 1}, 2: {'label': 'B', 'masked': 1}, 3: {'label': 'C', 'masked': 0}, 4: {'label': 'D', 'masked': 0}, 5: {'label': 'E', 'masked': 0}, 6: {'label': 'F', 'masked': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_nodes, test_nodes = train_test_split(\n",
    "\tlist(G.nodes), \n",
    "\ttest_size=0.2, \n",
    "\tshuffle=True, \n",
    "\trandom_state=42\n",
    ")\n",
    "\n",
    "print(train_nodes, test_nodes)\n",
    "nx.set_node_attributes(G, {node: 0 for node in train_nodes}, 'masked')\n",
    "nx.set_node_attributes(G, {node: 1 for node in test_nodes}, 'masked')\n",
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeDataView([(1, 2, {'label': '1', 'masked': False}), (1, 3, {'label': '2', 'masked': False}), (1, 6, {'label': '5', 'masked': False}), (2, 3, {'label': '6', 'masked': False}), (2, 5, {'label': '8', 'masked': False}), (2, 6, {'label': '9', 'masked': True}), (3, 4, {'label': '10', 'masked': False}), (3, 5, {'label': '11', 'masked': True}), (4, 5, {'label': '13', 'masked': False}), (4, 6, {'label': '14', 'masked': False}), (5, 6, {'label': '15', 'masked': False})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import torch\n",
    "from data_loading.data import GraphData\n",
    "import numpy as np\n",
    "\n",
    "edge_index = np.array(G.edges()).T\n",
    "transform = RandomLinkSplit(\n",
    "\tnum_val=0, \n",
    "\tnum_test=0.2, \n",
    "\tadd_negative_train_samples=True,\n",
    "\tneg_sampling_ratio=1,\n",
    "\tsplit_labels=True\n",
    ")\n",
    "\n",
    "train_data, _, test_data = transform(GraphData(\n",
    "\tedge_index=torch.tensor(edge_index), \n",
    "\tnum_nodes=G.number_of_nodes()\n",
    "))\n",
    "nx.set_edge_attributes(G, {tuple(edge): False for edge in train_data.pos_edge_label_index.T.tolist()}, 'masked')\n",
    "nx.set_edge_attributes(G, {tuple(edge): True for edge in test_data.pos_edge_label_index.T.tolist()}, 'masked')\n",
    "G.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
