{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading eamodelset from pickle\n",
      "Loaded eamodelset with 936 graphs\n",
      "Loaded eamodelset with 936 graphs\n",
      "Graphs: 936\n",
      "Loading graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6976c451f140aa85bd3c50076de391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating graphs:   0%|          | 0/936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9888c2b7a0d41a5a516db0e350c5a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing graphs:   0%|          | 0/936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AndJunction' 'ApplicationCollaboration' 'ApplicationComponent'\n",
      " 'ApplicationEvent' 'ApplicationFunction' 'ApplicationInteraction'\n",
      " 'ApplicationInterface' 'ApplicationProcess' 'ApplicationService'\n",
      " 'Artifact' 'Assessment' 'BusinessActor' 'BusinessCollaboration'\n",
      " 'BusinessEvent' 'BusinessFunction' 'BusinessInteraction'\n",
      " 'BusinessInterface' 'BusinessObject' 'BusinessProcess' 'BusinessRole'\n",
      " 'BusinessService' 'Capability' 'CommunicationNetwork' 'Constraint'\n",
      " 'Contract' 'CourseOfAction' 'DataObject' 'Deliverable' 'Device'\n",
      " 'DistributionNetwork' 'Driver' 'Equipment' 'Facility' 'Gap' 'Goal'\n",
      " 'Grouping' 'ImplementationEvent' 'Junction' 'Location' 'Material'\n",
      " 'Meaning' 'Node' 'OrJunction' 'Outcome' 'Path' 'Plateau' 'Principle'\n",
      " 'Product' 'Representation' 'Requirement' 'Resource' 'Stakeholder'\n",
      " 'SystemSoftware' 'TechnologyCollaboration' 'TechnologyEvent'\n",
      " 'TechnologyFunction' 'TechnologyInteraction' 'TechnologyInterface'\n",
      " 'TechnologyProcess' 'TechnologyService' 'Value' 'ValueStream'\n",
      " 'WorkPackage' None]\n",
      "['application' 'business' 'implementation_migration' 'motivation' 'other'\n",
      " 'strategy' 'technology' None]\n",
      "['Access' 'Aggregation' 'Assignment' 'Association' 'Composition' 'Flow'\n",
      " 'Influence' 'Realization' 'Serving' 'Specialization' 'Triggering']\n",
      "Train edge classes: {3: 15948, 10: 8318, 4: 21093, 2: 9601, 8: 10883, 7: 13058, 0: 7842, 1: 9421, 6: 2308, 9: 2364, 5: 6204}\n",
      "Test edge classes: {10: 2019, 3: 3861, 7: 3163, 4: 5257, 0: 1897, 2: 2363, 6: 579, 8: 2639, 5: 1542, 9: 602, 1: 2360}\n",
      "Loaded graph dataset\n"
     ]
    }
   ],
   "source": [
    "from data_loading.graph_dataset import GraphEdgeDataset\n",
    "from data_loading.models_dataset import ArchiMateModelDataset\n",
    "\n",
    "dataset = ArchiMateModelDataset('eamodelset')\n",
    "\n",
    "graph_data_params = dict(\n",
    "    test_ratio=0.2,\n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1,\n",
    "    distance=1,\n",
    "    use_embeddings=True,\n",
    "    embed_model_name='bert-base-uncased',\n",
    "    ckpt='results/eamodelset/edge_cls/checkpoint-8370'\n",
    ")\n",
    "\n",
    "print(\"Loading graph dataset\")\n",
    "graph_dataset = GraphEdgeDataset(dataset, **graph_data_params)\n",
    "print(\"Loaded graph dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNConv(\n",
       "  (aggregation): SumAggregation()\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): GATv2Conv(768, 128, heads=4)\n",
       "    (1-2): 2 x GATv2Conv(512, 128, heads=4)\n",
       "  )\n",
       "  (activation): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.gnn_layers import EdgeClassifer, GNNConv\n",
    "\n",
    "\n",
    "input_dim = 768\n",
    "\n",
    "cls_label = 'type'\n",
    "model_name = 'GATv2Conv'\n",
    "\n",
    "hidden_dim = 128\n",
    "output_dim = 128\n",
    "num_conv_layers = 3\n",
    "num_mlp_layers = 3\n",
    "num_heads = 4\n",
    "residual = True\n",
    "l_norm = False\n",
    "dropout = 0.3\n",
    "aggregation = 'sum'\n",
    "\n",
    "num_edges_label = f\"num_edges_{cls_label}\"\n",
    "assert hasattr(graph_dataset, num_edges_label), f\"Graph dataset does not have attribute {num_edges_label}\"\n",
    "num_classes = getattr(graph_dataset, num_edges_label)\n",
    "\n",
    "\n",
    "gnn_conv_model = GNNConv(\n",
    "    model_name=model_name,\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    out_dim=output_dim,\n",
    "    num_layers=num_conv_layers,\n",
    "    num_heads=num_heads,\n",
    "    residual=residual,\n",
    "    l_norm=l_norm,\n",
    "    dropout=dropout,\n",
    "    aggregation=aggregation,\n",
    "    edge_dim=768\n",
    ")\n",
    "\n",
    "mlp_predictor = EdgeClassifer(\n",
    "    input_dim=output_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_mlp_layers, \n",
    "    num_classes=num_classes,\n",
    "    bias=False,\n",
    ")\n",
    "\n",
    "gnn_conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "torch_dataset = graph_dataset.get_torch_geometric_data()\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    torch_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(train_edge_idx=[6737], test_edge_idx=[1668], train_pos_edge_label_index=[2, 6737], train_pos_edge_label=[6737], train_neg_edge_label_index=[2, 6737], train_neg_edge_label=[6737], test_pos_edge_label_index=[2, 1668], test_pos_edge_label=[1668], test_neg_edge_label_index=[2, 1668], test_neg_edge_label=[1668], overall_edge_index=[2, 8405], edge_index=[2, 6737], num_nodes=5418, x=[5418, 768], edge_attr=[8405, 768], node_type=[5418], node_layer=[5418], edge_type=[8405], batch=[5418], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNConv(\n",
       "  (aggregation): SumAggregation()\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): GATv2Conv(768, 128, heads=4)\n",
       "    (1-2): 2 x GATv2Conv(512, 128, heads=4)\n",
       "  )\n",
       "  (activation): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_conv_model.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5418, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_conv_model(data.x.to('cuda'), data.edge_index.to('cuda'), data.edge_attr[data.train_edge_idx].to('cuda')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "for file in os.listdir('datasets/eamodelset/processed-models'):\n",
    "    if os.path.isdir(os.path.join('datasets/eamodelset/processed-models', file)):\n",
    "        with open(f'datasets/eamodelset/processed-models/{file}/model.json') as f:\n",
    "            model = json.load(f)\n",
    "            json.dump(model, open(f'datasets/eamodelset/processed-models/{file}/model.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
