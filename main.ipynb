{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ontouml from pickle\n",
      "Loaded ontouml with 175 graphs\n",
      "Loaded ontouml with 175 graphs\n",
      "Graphs: 175\n"
     ]
    }
   ],
   "source": [
    "from utils import set_seed\n",
    "from data_loading.models_dataset import ArchiMateDataset, EcoreDataset, OntoUMLDataset\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "config_params = dict(\n",
    "    # reload=True,\n",
    "    min_enr = -1,\n",
    "    min_edges = 10,\n",
    "    # language = 'en',\n",
    ")\n",
    "\n",
    "# dataset = ArchiMateDataset('eamodelset', **config_params)\n",
    "# dataset = EcoreModelDataset('modelset', **config_params)\n",
    "dataset = OntoUMLDataset('ontouml', **config_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_graphs': 175,\n",
       " 'num_edges': 20220,\n",
       " 'num_nodes': 15890,\n",
       " 'average_nodes': '90.80',\n",
       " 'average_edges': '115.54',\n",
       " 'average_n2e_ratio': '0.83'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph dataset\n",
      "Number of duplicate graphs:  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2514314ef6cf4cfba8c4e93d85c64b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating edge graphs:   0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73203e7ff5374b06a49ce012ed17e39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding graphs:   0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701889ead07743078240a08c245a55d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-Loading graphs:   0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'abstract' 'abstract individual' 'activity' 'agent' 'atomic event'\n",
      " 'being present at ' 'belief' 'bringsabout' 'category' 'causal'\n",
      " 'characterization' 'collective' 'commitment' 'comparative'\n",
      " 'complex event' 'complexaction' 'complexevent' 'componentof' 'constitute'\n",
      " 'cr' 'crd' 'creation' 'cru' 'crud' 'datatype' 'derivation' 'disposition'\n",
      " 'endurant' 'enumeration' 'event' 'externaldependence' 'formal' 'goal'\n",
      " 'has part' 'historicaldependence' 'historicalrole' 'historicalrolemixin'\n",
      " 'humanagent' 'induces' 'instantiation' 'institutionalagent' 'intention'\n",
      " 'internal' 'kind' 'manifestation' 'material' 'material relation'\n",
      " 'mediation' 'memberof' 'mentalmode' 'mixin' 'mode' 'natural'\n",
      " 'nonperceivablequality' 'normative description' 'object' 'organization'\n",
      " 'part-of' 'participation' 'participational' 'partof' 'phase' 'phasemixin'\n",
      " 'pos-state' 'post state' 'pre-state' 'presentat' 'processual role'\n",
      " 'proposition' 'quale' 'quality' 'quality dimension' 'quality structure'\n",
      " 'quantity' 'r' 'relator' 'role' 'rolemixin' 'ru' 'service' 'set'\n",
      " 'situation' 'stringnominalstructure' 'structuration' 'subcollectionof'\n",
      " 'subkind' 'subquantityof' 'sum' 'termination' 'timepoint' 'triggers'\n",
      " 'trope' 'type' 'ufo-b' 'ufo-c' 'viewpoint']\n",
      "Setting num_nodes_ stereotype 97\n",
      "Edge Classes:  [None]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096a7593d90343029f11d18dfed50890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating edge classes:   0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {0}\n",
      "Test classes: {0}\n",
      "Number of classes in training set: 1\n",
      "Number of classes in test set: 1\n",
      "Train edge classes: {0: 16153}\n",
      "Test edge classes: {0: 3947}\n",
      "Loaded graph dataset\n"
     ]
    }
   ],
   "source": [
    "from data_loading.graph_dataset import GraphEdgeDataset\n",
    "import utils\n",
    "\n",
    "utils.set_seed(42)\n",
    "\n",
    "graph_data_params = dict(\n",
    "    reload=True,\n",
    "    test_ratio=0.2,\n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1,\n",
    "    distance=0,\n",
    "    random_embed_dim=1,\n",
    "    use_attributes=True,\n",
    "    use_edge_label=True,\n",
    "    use_edge_types=True,\n",
    "    use_node_types=True,\n",
    "    use_special_tokens=True,\n",
    "    # use_embeddings=True,\n",
    "    # embed_model_name='bert-base-cased',\n",
    "    # ckpt='results/eamodelset/lp/10_att_0_nt_0/checkpoint-177600',\n",
    "    limit = -1,\n",
    ")\n",
    "\n",
    "print(\"Loading graph dataset\")\n",
    "graph_edge_dataset = GraphEdgeDataset(dataset, **graph_data_params)\n",
    "print(\"Loaded graph dataset\")\n",
    "\n",
    "# texts = graph_edge_dataset.get_link_prediction_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db6958fabbc491b871472e05f170fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding node graphs:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaefe647c72342458730467e867d0081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating graphs:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AndJunction' 'ApplicationCollaboration' 'ApplicationComponent'\n",
      " 'ApplicationEvent' 'ApplicationFunction' 'ApplicationInteraction'\n",
      " 'ApplicationInterface' 'ApplicationProcess' 'ApplicationService'\n",
      " 'Artifact' 'Assessment' 'BusinessActor' 'BusinessCollaboration'\n",
      " 'BusinessEvent' 'BusinessFunction' 'BusinessInteraction'\n",
      " 'BusinessInterface' 'BusinessObject' 'BusinessProcess' 'BusinessRole'\n",
      " 'BusinessService' 'Capability' 'CommunicationNetwork' 'Constraint'\n",
      " 'Contract' 'CourseOfAction' 'DataObject' 'Deliverable' 'Device'\n",
      " 'DistributionNetwork' 'Driver' 'Equipment' 'Facility' 'Gap' 'Goal'\n",
      " 'Grouping' 'ImplementationEvent' 'Junction' 'Location' 'Material'\n",
      " 'Meaning' 'Node' 'OrJunction' 'Outcome' 'Path' 'Plateau' 'Principle'\n",
      " 'Product' 'Representation' 'Requirement' 'Resource' 'Stakeholder'\n",
      " 'SystemSoftware' 'TechnologyCollaboration' 'TechnologyEvent'\n",
      " 'TechnologyFunction' 'TechnologyInteraction' 'TechnologyInterface'\n",
      " 'TechnologyProcess' 'TechnologyService' 'Value' 'ValueStream'\n",
      " 'WorkPackage' None]\n",
      "Setting num_nodes_ type 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d15df71b7a4cf5811b0adcaa0c53f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating node classes:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63}\n",
      "Test classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63}\n",
      "Number of classes in training set: 64\n",
      "Number of classes in test set: 64\n",
      "['application' 'business' 'implementation_migration' 'motivation' 'other'\n",
      " 'strategy' 'technology' None]\n",
      "Setting num_nodes_ layer 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461555170f684697a337904ed75c06f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating node classes:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Test classes: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Number of classes in training set: 8\n",
      "Number of classes in test set: 8\n",
      "Edge Classes:  ['Access' 'Aggregation' 'Assignment' 'Association' 'Composition' 'Flow'\n",
      " 'Influence' 'Realization' 'Serving' 'Specialization' 'Triggering']\n",
      "Node label: type\n",
      "Train Node classes: {6: 708, 26: 2661, 4: 2366, 7: 1484, 2: 3827, 11: 1376, 8: 1821, 41: 1248, 21: 1632, 40: 138, 35: 2259, 17: 3385, 49: 1308, 60: 187, 3: 251, 20: 1324, 14: 1490, 25: 574, 18: 2667, 12: 199, 9: 880, 61: 152, 47: 486, 28: 427, 10: 566, 51: 461, 43: 370, 50: 195, 23: 229, 38: 171, 30: 416, 46: 789, 62: 316, 19: 1139, 52: 1167, 54: 52, 59: 860, 57: 282, 55: 258, 37: 205, 48: 365, 16: 2113, 34: 662, 15: 157, 13: 480, 22: 280, 24: 112, 5: 86, 0: 64, 44: 132, 58: 146, 1: 161, 31: 102, 29: 36, 42: 63, 53: 159, 32: 84, 45: 163, 27: 135, 39: 41, 36: 39, 63: 87, 33: 87, 56: 26}\n",
      "Test Node classes: {4: 612, 7: 374, 2: 954, 11: 393, 26: 677, 21: 436, 17: 889, 35: 601, 3: 58, 20: 353, 14: 412, 9: 235, 18: 775, 25: 122, 19: 316, 41: 308, 61: 44, 38: 40, 47: 109, 10: 144, 8: 396, 52: 291, 37: 51, 48: 107, 6: 170, 46: 163, 49: 323, 34: 167, 30: 100, 13: 129, 16: 579, 60: 48, 51: 90, 59: 199, 28: 104, 22: 60, 56: 5, 12: 65, 55: 68, 23: 55, 44: 40, 50: 59, 29: 10, 62: 75, 5: 33, 32: 19, 39: 9, 24: 28, 0: 16, 15: 39, 40: 25, 57: 65, 63: 27, 58: 23, 42: 14, 54: 14, 31: 21, 45: 39, 33: 29, 53: 37, 43: 82, 1: 41, 36: 7, 27: 26}\n",
      "Node label: layer\n",
      "Train Node classes: {0: 13365, 1: 15293, 6: 6180, 5: 2553, 3: 5126, 4: 2762, 2: 740, 7: 87}\n",
      "Test Node classes: {0: 3315, 1: 4194, 5: 661, 4: 722, 6: 1508, 3: 1197, 2: 176, 7: 27}\n",
      "Loaded graph dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c707d063ca41faba6bbf26d2da7b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting node classification data:   0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data\n",
      "['<node_begin>interface prototype<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 3<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>method 2<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>type:ApplicationFunction method 1<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Association<edge_end> <node_begin>clone<node_end>\\n<node_begin>interface prototype<node_end> <edge_begin>type:Serving<edge_end> <node_begin>class client<node_end>', '<node_begin>instance A<node_end> <edge_begin>type:Association<edge_end> <node_begin>type:ApplicationComponent subclass prototype A<node_end>', '<node_begin>construct algoritm<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess construct some object<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Realization<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Realization<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>construct algoritm<node_end> <edge_begin>type:Composition<edge_end> <node_begin>type:ApplicationFunction clone instance<node_end>', '<node_begin>clone<node_end>', '<node_begin>method 3<node_end>', '<node_begin>step on new instance<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>step on new instance<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 3<node_end>', '<node_begin>method 3<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>method 3<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationFunction method 3<node_end>', '<node_begin>create subclass proto<node_end> <edge_begin>type:Access<edge_end> <node_begin>type:DataObject instance A<node_end>\\n<node_begin>create subclass proto<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:ApplicationProcess create client<node_end>', '<node_begin>step on new instance<node_end> <edge_begin>type:Flow<edge_end> <node_begin>method 2<node_end>', '<node_begin>method 1<node_end>']\n",
      "['<node_begin>clone<node_end> <edge_begin>type:Serving<edge_end> <node_begin>get specific result A<node_end>', '<node_begin>get specific result A<node_end>', '<node_begin>class client<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction construct algoritm<node_end>\\n<node_begin>class client<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationProcess create client<node_end>', '<node_begin>clone<node_end> <edge_begin>type:Serving<edge_end> <node_begin>type:ApplicationFunction clone instance<node_end>\\n<node_begin>clone<node_end> <edge_begin>type:Flow<edge_end> <node_begin>clone<node_end>', '<node_begin>method 2<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationProcess step on new instance<node_end>\\n<node_begin>method 2<node_end> <edge_begin><edge_end> <node_begin>type:ApplicationFunction method 2<node_end>', '<node_begin>President/CEO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor COO<node_end>\\n<node_begin>President/CEO<node_end> <edge_begin><edge_end> <node_begin>CTO<node_end>', '<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor human resources<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>compliance<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor business development<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor accounting & finance<node_end>\\n<node_begin>COO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor legal<node_end>', '<node_begin>compliance<node_end>', '<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Product Development/Project Manager<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Infrastructure Engineer<node_end>\\n<node_begin>CTO<node_end> <edge_begin><edge_end> <node_begin>type:BusinessActor Sr. WP developer/architect<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Sr. Blockchain developer<node_end>\\n<node_begin>CTO<node_end> <edge_begin>type:Flow<edge_end> <node_begin>type:BusinessActor Sr. hybrid mobile developer<node_end>', '<node_begin>DB<node_end>']\n",
      "46019\n",
      "46019\n",
      "11773\n",
      "11773\n"
     ]
    }
   ],
   "source": [
    "from data_loading.graph_dataset import GraphNodeDataset\n",
    "\n",
    "graph_data_params = dict(\n",
    "    reload=True,\n",
    "    test_ratio=0.2,\n",
    "    distance=1,\n",
    "    random_embed_dim=1,\n",
    "    use_attributes=True,\n",
    "    use_node_types=True,\n",
    "    use_edge_label=True,\n",
    "    use_edge_types=True,\n",
    "    use_special_tokens=True,\n",
    "    # use_embeddings=True,\n",
    "    # embed_model_name='bert-base-cased',\n",
    "    # ckpt='results/eamodelset/lp/10_att_0_nt_0/checkpoint-177600',\n",
    "    node_cls_label='type',\n",
    ")\n",
    "\n",
    "    # graph_data_params = dict(\n",
    "    #     distance=args.distance,\n",
    "    #     reload=args.reload,\n",
    "    #     test_ratio=args.test_ratio,\n",
    "    #     use_attributes=args.use_attributes,\n",
    "    #     use_node_types=args.use_node_types,\n",
    "    #     use_edge_types=args.use_edge_types,\n",
    "    #     use_edge_label=args.use_edge_label,\n",
    "    #     use_special_tokens=args.use_special_tokens,\n",
    "    #     no_labels=args.no_labels,\n",
    "    #     node_cls_label=args.cls_label,\n",
    "    #     use_embeddings=args.use_embeddings,\n",
    "    #     embed_model_name=args.embed_model_name,\n",
    "    #     ckpt=args.ckpt,\n",
    "    # )\n",
    "\n",
    "\n",
    "print(\"Loading graph dataset\")\n",
    "graph_node_dataset = GraphNodeDataset(dataset, **graph_data_params)\n",
    "print(\"Loaded graph dataset\")\n",
    "data = graph_node_dataset.get_node_classification_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46019"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = sum([v for k, v in data.items() if k.startswith('train') and not k.endswith('classes')], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XYZ'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='XYZ')\n",
    "\n",
    "b = B()\n",
    "b.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test = data['train_nodes'], data['test_nodes']\n",
    "y_train, y_test = data['train_node_classes'], data['test_node_classes']\n",
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'), verbose=True)\n",
    "\n",
    "print(\"Fitting SVM classifier\")\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Predicting\")\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Step 1: Train a Word2Vec model\n",
    "sentences = [text.split() for text in data['train_nodes'] + data['test_nodes']]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Step 2: Use the embeddings to transform the dataset\n",
    "def get_embeddings(texts, model):\n",
    "\tembeddings = []\n",
    "\tfor text in texts:\n",
    "\t\twords = text.split()\n",
    "\t\tword_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "\t\tif word_vectors:\n",
    "\t\t\tembeddings.append(np.mean(word_vectors, axis=0))\n",
    "\t\telse:\n",
    "\t\t\tembeddings.append(np.zeros(model.vector_size))\n",
    "\treturn np.array(embeddings)\n",
    "\n",
    "X_train_embeddings = get_embeddings(data['train_nodes'], word2vec_model)\n",
    "X_test_embeddings = get_embeddings(data['test_nodes'], word2vec_model)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(data['train_node_classes'])\n",
    "y_test = label_encoder.transform(data['test_node_classes'])\n",
    "\n",
    "# Step 3: Train an SVM classifier using the embeddings\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train_embeddings, y_train)\n",
    "y_pred_svm = svm_classifier.predict(X_test_embeddings)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Step 4: Train a neural network classifier using the embeddings\n",
    "class SimpleNN(nn.Module):\n",
    "\tdef __init__(self, input_dim, output_dim):\n",
    "\t\tsuper(SimpleNN, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(input_dim, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, output_dim)\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = torch.relu(self.fc1(x))\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn x\n",
    "\n",
    "input_dim = X_train_embeddings.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = SimpleNN(input_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_embeddings, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_embeddings, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\tmodel.train()\n",
    "\tfor X_batch, y_batch in train_loader:\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(X_batch)\n",
    "\t\tloss = criterion(outputs, y_batch)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\tprint(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluate the neural network\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\toutputs = model(X_test_tensor)\n",
    "\t_, y_pred_nn = torch.max(outputs, 1)\n",
    "\ty_pred_nn = y_pred_nn.numpy()\n",
    "\tprint(\"Neural Network Classification Report:\")\n",
    "\tprint(classification_report(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import W2V_CONFIG\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "from typing import List, Union\n",
    "from embeddings.common import Embedder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class TFIDFEmbedder(Embedder):\n",
    "    def __init__(self, texts: List[str]):\n",
    "        print(\"TFIDFEmbedder: Training TF-IDF model\")\n",
    "        self.model = TfidfVectorizer()\n",
    "        self.model.fit(texts)\n",
    "        print(\"TFIDFEmbedder: Model trained\")\n",
    "\n",
    "    @property\n",
    "    def embedding_dim(self) -> int:\n",
    "        return len(self.model.get_feature_names_out())\n",
    "    \n",
    "    def embed(self, text: Union[str, List[str]]):\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        return torch.tensor(self.model.transform(text).toarray()[0])\n",
    "\n",
    "class Word2VecEmbedder(Embedder):\n",
    "    def __init__(self, texts: List[str]):\n",
    "        print(\"Word2VecEmbedder: Training Word2Vec model\")\n",
    "        self.model = Word2Vec(texts, **W2V_CONFIG)\n",
    "        print(\"Word2VecEmbedder: Word2Vec model trained\")\n",
    "\n",
    "    @property\n",
    "    def embedding_dim(self) -> int:\n",
    "        return self.model.vector_size\n",
    "    \n",
    "    def embed(self, text: Union[str, List[str]]):\n",
    "        if isinstance(text, str):\n",
    "            text = text.split()\n",
    "        word_vectors = [self.model.wv[word] for word in text if word in self.model.wv]\n",
    "        if word_vectors:\n",
    "            return torch.tensor(word_vectors).mean(dim=0)\n",
    "        else:\n",
    "            return torch.zeros(self.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embedder = Word2VecEmbedder(texts)\n",
    "tfidf_embedder = TFIDFEmbedder(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_node(1, label='A')\n",
    "G.add_node(2, label='B')\n",
    "G.add_node(3, label='C')\n",
    "G.add_node(4, label='D')\n",
    "G.add_node(5, label='E')\n",
    "G.add_node(6, label='F')\n",
    "\n",
    "G.add_edge(1, 2, label='1')\n",
    "G.add_edge(1, 3, label='2')\n",
    "G.add_edge(1, 6, label='5')\n",
    "G.add_edge(2, 3, label='6')\n",
    "G.add_edge(2, 5, label='8')\n",
    "G.add_edge(2, 6, label='9')\n",
    "G.add_edge(3, 4, label='10')\n",
    "G.add_edge(3, 5, label='11')\n",
    "G.add_edge(4, 5, label='13')\n",
    "G.add_edge(4, 6, label='14')\n",
    "G.add_edge(5, 6, label='15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 3, 5, 4] [1, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NodeDataView({1: {'label': 'A', 'masked': 1}, 2: {'label': 'B', 'masked': 1}, 3: {'label': 'C', 'masked': 0}, 4: {'label': 'D', 'masked': 0}, 5: {'label': 'E', 'masked': 0}, 6: {'label': 'F', 'masked': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_nodes, test_nodes = train_test_split(\n",
    "\tlist(G.nodes), \n",
    "\ttest_size=0.2, \n",
    "\tshuffle=True, \n",
    "\trandom_state=42\n",
    ")\n",
    "\n",
    "print(train_nodes, test_nodes)\n",
    "nx.set_node_attributes(G, {node: 0 for node in train_nodes}, 'masked')\n",
    "nx.set_node_attributes(G, {node: 1 for node in test_nodes}, 'masked')\n",
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeDataView([(1, 2, {'label': '1', 'masked': False}), (1, 3, {'label': '2', 'masked': False}), (1, 6, {'label': '5', 'masked': False}), (2, 3, {'label': '6', 'masked': False}), (2, 5, {'label': '8', 'masked': False}), (2, 6, {'label': '9', 'masked': True}), (3, 4, {'label': '10', 'masked': False}), (3, 5, {'label': '11', 'masked': True}), (4, 5, {'label': '13', 'masked': False}), (4, 6, {'label': '14', 'masked': False}), (5, 6, {'label': '15', 'masked': False})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import torch\n",
    "from data_loading.data import GraphData\n",
    "import numpy as np\n",
    "\n",
    "edge_index = np.array(G.edges()).T\n",
    "transform = RandomLinkSplit(\n",
    "\tnum_val=0, \n",
    "\tnum_test=0.2, \n",
    "\tadd_negative_train_samples=True,\n",
    "\tneg_sampling_ratio=1,\n",
    "\tsplit_labels=True\n",
    ")\n",
    "\n",
    "train_data, _, test_data = transform(GraphData(\n",
    "\tedge_index=torch.tensor(edge_index), \n",
    "\tnum_nodes=G.number_of_nodes()\n",
    "))\n",
    "nx.set_edge_attributes(G, {tuple(edge): False for edge in train_data.pos_edge_label_index.T.tolist()}, 'masked')\n",
    "nx.set_edge_attributes(G, {tuple(edge): True for edge in test_data.pos_edge_label_index.T.tolist()}, 'masked')\n",
    "G.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
