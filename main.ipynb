{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datasets_dir = 'datasets'\n",
    "ecore_json_path = os.path.join(datasets_dir, 'ecore_555/ecore_555.jsonl')\n",
    "mar_json_path = os.path.join(datasets_dir, 'mar-ecore-github/ecore-github.jsonl')\n",
    "modelsets_uml_json_path = os.path.join(datasets_dir, 'modelset/uml.jsonl')\n",
    "modelsets_ecore_json_path = os.path.join(datasets_dir, 'modelset/ecore.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ecore_555 from pickle\n",
      "Loaded ecore_555 with 281 graphs\n",
      "Loaded ecore_555 with 281 graphs\n",
      "Graphs: 281\n",
      "Loading modelset from pickle\n",
      "Loaded modelset with 830 graphs\n",
      "Loaded modelset with 830 graphs\n",
      "Graphs: 830\n",
      "Loading mar-ecore-github from pickle\n",
      "Loaded mar-ecore-github with 5388 graphs\n",
      "Loaded mar-ecore-github with 5388 graphs\n",
      "Graphs: 5388\n"
     ]
    }
   ],
   "source": [
    "from data_loading.data import ModelDataset\n",
    "\n",
    "config_params = dict(\n",
    "    timeout = 120,\n",
    "    min_enr = 1.2,\n",
    "    min_edges = 10\n",
    ")\n",
    "ecore = ModelDataset('ecore_555', reload=False, **config_params)\n",
    "modelset = ModelDataset('modelset', reload=False, remove_duplicates=True, **config_params)\n",
    "mar = ModelDataset('mar-ecore-github', reload=False, **config_params)\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    'ecore': ecore,\n",
    "    'modelset': modelset,\n",
    "    'mar': mar\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f91b86976a4637adf0f5efc4fd80d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ecore_555:   0%|          | 0/281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_loading.graph_dataset import GraphDataset\n",
    "\n",
    "graph_data_params = dict(\n",
    "    distance=2,\n",
    "    reload=False,\n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1,\n",
    ")\n",
    "\n",
    "ecore_graph_dataset = GraphDataset(ecore, **graph_data_params)\n",
    "# modelset_graph_dataset = GraphDataset(modelset, **graph_data_params)\n",
    "# mar_graph_dataset = GraphDataset(mar, **graph_data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[45, 768], edge_index=[2, 45], edge_attr=[45, 768], y=1, overall_edge_index=[2, 56], train_pos_edge_label_index=[2, 45], train_pos_edge_label=[45], train_neg_edge_label_index=[2, 45], train_neg_edge_label=[45], test_pos_edge_label_index=[2, 11], test_pos_edge_label=[11], test_neg_edge_label_index=[2, 11], test_neg_edge_label=[11], num_nodes=45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ecore_graph_dataset, key=lambda d: d.x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecore_graph_dataset[0].x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "ecore_loader_train = DataLoader(ecore_graph_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class MultiTaskGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_edge_types):\n",
    "        super(MultiTaskGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.link_pred_head = nn.Linear(hidden_channels * 2, 1)  # Link prediction head\n",
    "        self.edge_class_head = nn.Linear(hidden_channels * 2, num_edge_types)  # Edge classification head\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x: Node features [num_nodes, in_channels]\n",
    "        # edge_index: Graph connectivity [2, num_edges]\n",
    "        \n",
    "        # GNN layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # For link prediction and edge classification, we use edge embeddings\n",
    "        row, col = edge_index\n",
    "        edge_features = torch.cat([x[row], x[col]], dim=1)  # [num_edges, hidden_channels*2]\n",
    "        \n",
    "        # Link prediction\n",
    "        link_pred = torch.sigmoid(self.link_pred_head(edge_features)).squeeze()  # [num_edges]\n",
    "        \n",
    "        # Edge classification\n",
    "        edge_class = self.edge_class_head(edge_features)  # [num_edges, num_edge_types]\n",
    "        \n",
    "        return link_pred, edge_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinkPredictor(\n",
       "  (conv): GNNConv(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): GATv2Conv(768, 64, heads=4)\n",
       "      (1-2): 2 x GATv2Conv(256, 64, heads=4)\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (link_pred_head): FeedForward(\n",
       "    (ff): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=64, bias=False)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (edge_class_head): FeedForward(\n",
       "    (ff): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=64, bias=False)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=3, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.gnn_layers import LinkPredictor\n",
    "from settings import device\n",
    "\n",
    "lp_model = LinkPredictor(\n",
    "    'GATv2Conv',\n",
    "    ecore_graph_dataset[0].x.shape[1],\n",
    "    64,\n",
    "    3,\n",
    "    num_heads=4,\n",
    "    dropout = 0.1,\n",
    "    residual = False, \n",
    "    use_edge_attrs = True,\n",
    "    edge_attrs_dim=768,\n",
    "    add_classification_head=True,\n",
    "    num_edge_types=3,\n",
    "    ff_hidden_dim=64\n",
    ")\n",
    "\n",
    "lp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in ecore_loader_train:\n",
    "    batch = batch.to(device)\n",
    "    out = lp_model(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4335, 0.4738, 0.4692,  ..., 0.4525, 0.4680, 0.4391], device='cuda:0',\n",
       "        grad_fn=<SqueezeBackward0>),\n",
       " tensor([[-0.0176,  0.0209,  0.1657],\n",
       "         [-0.0385, -0.0550,  0.1525],\n",
       "         [-0.0484, -0.0621,  0.0976],\n",
       "         ...,\n",
       "         [-0.0576, -0.1183,  0.0383],\n",
       "         [-0.0693, -0.0172,  0.0558],\n",
       "         [-0.0091,  0.0272,  0.0776]], device='cuda:0', grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6956, Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.loader import DataLoader\n",
    "# from torch_geometric.nn import GCNConv\n",
    "# from torch_geometric.nn.aggr import SortAggregation\n",
    "# import networkx as nx\n",
    "# from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "\n",
    "# def remap_node_indices(subgraph, center_node):\n",
    "#     mapping = {node: i for i, node in enumerate(subgraph.nodes())}\n",
    "#     subgraph = nx.relabel_nodes(subgraph, mapping)\n",
    "#     sub_edge_index = torch.tensor(list(subgraph.edges)).t().contiguous()\n",
    "#     sub_x = torch.ones(subgraph.number_of_nodes(), 1)  # Example node features\n",
    "#     center_node_idx = mapping[center_node]\n",
    "#     return sub_x, sub_edge_index, center_node_idx\n",
    "\n",
    "# # Prepare the train and test datasets for SEAL model\n",
    "# class SEALGraphData:\n",
    "#     def __init__(\n",
    "#             self, \n",
    "#             graph,\n",
    "#             edge_index,\n",
    "#             pos_edge_index,\n",
    "#             neg_edge_index,\n",
    "#             hops=1\n",
    "#         ):\n",
    "#         self.edge_index = edge_index\n",
    "#         self.pos_edge_index = pos_edge_index\n",
    "#         self.neg_edge_index = neg_edge_index\n",
    "#         self.graph = graph\n",
    "#         self.hops = hops\n",
    "\n",
    "\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.pos_edge_index.size(1) + self.neg_edge_index.size(1)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if idx < self.pos_edge_index.size(1):\n",
    "#             u, v = self.pos_edge_index[:, idx]\n",
    "#             y = 1\n",
    "#         else:\n",
    "#             u, v = self.neg_edge_index[:, idx - self.pos_edge_index.size(1)]\n",
    "#             y = 0\n",
    "\n",
    "#         subgraph = nx.ego_graph(self.graph, u.item(), radius=self.hops)\n",
    "#         subgraph = nx.subgraph(subgraph, list(subgraph.nodes) + [v.item()])\n",
    "#         sub_x, sub_edge_index, center_node_idx = remap_node_indices(subgraph, u.item())\n",
    "\n",
    "#         return Data(\n",
    "#             x=sub_x, \n",
    "#             edge_index=sub_edge_index, \n",
    "#             y=y, \n",
    "#             center_node_idx=center_node_idx\n",
    "#         )\n",
    "\n",
    "\n",
    "# def get_link_prediction_train_test_graph_data(\n",
    "#         graph, \n",
    "#         num_val=0, \n",
    "#         num_test=0.2, \n",
    "#         add_negative_train_samples=True,\n",
    "#         neg_sampling_ratio=1,\n",
    "#     ):\n",
    "#     transform = RandomLinkSplit(\n",
    "#         num_val=num_val, \n",
    "#         num_test=num_test, \n",
    "#         neg_sampling_ratio=neg_sampling_ratio,\n",
    "#         add_negative_train_samples=add_negative_train_samples,\n",
    "#         split_labels=True\n",
    "#     )\n",
    "\n",
    "#     # Apply the transform\n",
    "#     train_data, _, test_data = transform(\n",
    "#         Data(\n",
    "#             edge_index=graph.edge_index, \n",
    "#             num_nodes=ecore_graph.number_of_nodes()\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     return train_data, test_data\n",
    "\n",
    "#     # train_graph_data = SEALGraphData(\n",
    "#     #     graph, \n",
    "#     #     train_data.edge_index, \n",
    "#     #     train_data.pos_edge_label_index, \n",
    "#     #     train_data.neg_edge_label_index,\n",
    "#     #     hops=hops\n",
    "    \n",
    "#     # )\n",
    "\n",
    "#     # test_graph_data = SEALGraphData(\n",
    "#     #     graph, \n",
    "#     #     test_data.edge_index, \n",
    "#     #     test_data.pos_edge_label_index, \n",
    "#     #     test_data.neg_edge_label_index,\n",
    "#     #     hops=hops\n",
    "#     # )\n",
    "\n",
    "#     # return train_graph_data, test_graph_data\n",
    "    \n",
    "\n",
    "# train_data, test_data = get_link_prediction_train_test_graph_data(ecore_graph)\n",
    "# # Create train and test dataloaders\n",
    "# batch_size = 32\n",
    "\n",
    "# # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# # test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gnn_layers import GNNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
